import os
from pathlib import Path
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë“±ì„ ë¡œë“œ
load_dotenv()

# --- 1. ì„¤ì • ---
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent.parent

# PDF íŒŒì¼ ê²½ë¡œ ëª©ë¡
PDF_FILES = [
    BASE_DIR / "data" / "pdf" / "2-2. 2020 í•œêµ­ì¸ ì˜ì–‘ì†Œ ì„­ì·¨ê¸°ì¤€ - ë¹„íƒ€ë¯¼.pdf",
    BASE_DIR / "data" / "pdf" / "2-3. 2020 í•œêµ­ì¸ ì˜ì–‘ì†Œ ì„­ì·¨ê¸°ì¤€ - ë¬´ê¸°ì§ˆ.pdf",
]

# FAISS ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  ê²½ë¡œ
FAISS_INDEX_PATH = str(BASE_DIR / "faiss_index_rda")

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ìš”ì²­í•˜ì‹  E5 ê³„ì—´ ë©€í‹°ë§ê¶ ëª¨ë¸)
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large"


def build_rag_index():
    """
    PDF íŒŒì¼ë“¤ì„ ì½ì–´ FAISS ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ RAG ì¸ë±ìŠ¤ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    all_pages = []
    for pdf_path in PDF_FILES:
        if not pdf_path.exists():
            print(f"âš ï¸ ê²½ê³ : '{pdf_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        print(f"ğŸ“„ '{pdf_path.name}' íŒŒì¼ ë¡œë”© ì¤‘...")
        # PyPDFLoaderëŠ” í˜ì´ì§€ë³„ë¡œ ë¬¸ì„œë¥¼ ë‚˜ëˆ„ê³ , íŒŒì¼ëª…ê³¼ í˜ì´ì§€ ë²ˆí˜¸ ë©”íƒ€ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load_and_split()
        all_pages.extend(pages)

    if not all_pages:
        print("ğŸš¨ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ì–´ ì¸ë±ìŠ¤ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    print(f"\nğŸ“š ì´ {len(all_pages)} í˜ì´ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ì´ì œ í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•©ë‹ˆë‹¤...")
    # í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í•  (ì²­í‚¹)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100,
    )
    docs = text_splitter.split_documents(all_pages)
    print(f"âœ‚ï¸ ì´ {len(docs)}ê°œì˜ ë¬¸ì„œ ì¡°ê°(ì²­í¬)ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print(f"\nğŸ§  '{EMBEDDING_MODEL_NAME}' ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    # HuggingFaceì˜ E5 ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

    print("ğŸ’¾ FAISS ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤...")
    # FAISS ë²¡í„° DB ìƒì„± ë° ì €ì¥
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(FAISS_INDEX_PATH)

    print(f"âœ… RAG ì¸ë±ìŠ¤ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì €ì¥ ê²½ë¡œ: '{FAISS_INDEX_PATH}'")


def search_rag(query: str, k: int = 5):
    """
    ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ë„ ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    if not Path(FAISS_INDEX_PATH).exists():
        print("ğŸš¨ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `build_rag_index()`ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None, None

    print(f"\nğŸ” ì§ˆë¬¸: '{query}'")
    print("... FAISS ì¸ë±ìŠ¤ ë¡œë”© ë° ê²€ìƒ‰ ì¤‘ ...")

    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)

    # ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (MMRì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ì˜ ë‹¤ì–‘ì„± í™•ë³´)
    retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={'k': k})
    retrieved_docs = retriever.invoke(query)

    print(f"\nâœ… ì´ {len(retrieved_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # --- 7. ë‹µë³€ ìƒì„±ìš© ì»¨í…ìŠ¤íŠ¸ íŒ¨í‚¹ (ì¸ìš©í‘œê¸° í¬í•¨) ---
    context_for_llm = ""
    for i, doc in enumerate(retrieved_docs):
        source_file = Path(doc.metadata['source']).name
        page_num = doc.metadata['page'] + 1  # í˜ì´ì§€ ë²ˆí˜¸ëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1
        context_for_llm += f"[ì¶œì²˜ {i+1}: {source_file}, {page_num}í˜ì´ì§€]\n"
        context_for_llm += f"{doc.page_content}\n\n"
    
    return retrieved_docs, context_for_llm


def answer_with_rag(query: str, context: str):
    """
    ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ í†µí•´ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("\nğŸ’¬ LLMì„ í†µí•´ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì œê³µëœ 'ì¶œì²˜'ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì˜ì–‘ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ê° ë‚´ìš©ì˜ ê·¼ê±°ê°€ ëœ 'ì¶œì²˜' ë²ˆí˜¸ë¥¼ ë¬¸ì¥ ëì— [ì¶œì²˜ 1], [ì¶œì²˜ 2]ì™€ ê°™ì´ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì œê³µëœ ë‚´ìš©ì— ë‹µì´ ì—†ìœ¼ë©´ 'ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë§í•˜ì„¸ìš”."),
        ("human", "ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.\n\n[ì°¸ê³  ë‚´ìš©]\n{context}\n\n[ì§ˆë¬¸]\n{question}")
    ])
    
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    chain = (
        {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )

    # chain.invokeë¥¼ í˜¸ì¶œí•  ë•Œ questionê³¼ contextë¥¼ í•¨ê»˜ ì „ë‹¬
    answer = chain.invoke({"question": query, "context": context})
    return answer


if __name__ == "__main__":
    # --- 1ë‹¨ê³„: RAG ì¸ë±ìŠ¤ ìƒì„± (ìµœì´ˆ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤) ---
    # build_rag_index()

    # --- 2ë‹¨ê³„: ìƒì„±ëœ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ë° ë‹µë³€ ---
    # ì˜ˆì‹œ ì§ˆë¬¸
    my_question = "30ëŒ€ ë‚¨ì„±ì˜ ë§ˆê·¸ë„¤ìŠ˜ ê¶Œì¥ ì„­ì·¨ëŸ‰ê³¼ ìƒí•œ ì„­ì·¨ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?"
    
    # RAG ê²€ìƒ‰
    docs, context = search_rag(my_question)
    
    if context:
        # ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì¶œì²˜ì™€ ë‚´ìš© í™•ì¸
        print("\n--- [ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸] ---\n")
        print(context)
        
        # LLMì„ í†µí•œ ë‹µë³€ ìƒì„±
        final_answer = answer_with_rag(my_question, context)
        
        print("\n--- [ìµœì¢… ë‹µë³€] ---\n")
        print(final_answer)

