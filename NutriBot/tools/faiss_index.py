from dotenv import load_dotenv
load_dotenv()

from sqlalchemy import create_engine, text
# from langchain_community.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document

# 1. PostgreSQLì—ì„œ ì œí’ˆ ë°ì´í„° ë¡œë“œ
def load_supplements_from_db():
    engine = create_engine("postgresql://postgres:67368279@localhost:5432/NutriBot")
    with engine.connect() as conn:
        # âœ… 3ê°œ í…Œì´ë¸”ì„ JOINí•˜ì—¬ ì œí’ˆ ì •ë³´ì™€ ì„±ë¶„ ì •ë³´ë¥¼ í•¨ê»˜ ê°€ì ¸ì˜µë‹ˆë‹¤.
        result = conn.execute(text("""
            SELECT 
                s.product_code, s.title, s.brand, s.avg_rating, s.reviews_count, s.description,
                i.name as ingredient_name, si.amount_per_serving, si.amount_unit, s.supplement_id
            FROM supplements
            LEFT JOIN supplement_ingredients si ON s.supplement_id = si.supplement_id
            LEFT JOIN ingredients i ON si.ingredient_id = i.ingredient_id
            ORDER BY s.product_code
        """))
        rows = result.fetchall()

        # âœ… ì›ë³¸ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ parsed_ingredients ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        parsed_json_path = Path(__file__).resolve().parent.parent / "data" / "json" / "parsed_supplements_output.json"
        with open(parsed_json_path, "r", encoding="utf-8") as f:
            parsed_data = json.load(f)
        
        # product_codeë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        parsed_ingredients_map = {}
        for item in parsed_data:
            if item.get("Product code"):
                parsed_ingredients_map[item["Product code"]] = item.get("parsed_ingredients", [])

        # âœ… ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì œí’ˆë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ supplement_factsë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
        products_dict = {}
        for row in rows:
            product_code = row[0]
            if product_code not in products_dict:
                products_dict[product_code] = {
                    "product_code": product_code,
                    "title": row[1],
                    "brand": row[2],
                    "avg_rating": float(row[3]) if row[3] else 0.0,
                    "reviews_count": int(row[4]) if row[4] else 0,
                    "description": row[5] or "",
                    "supplement_facts": [],
                    "parsed_ingredients": parsed_ingredients_map.get(product_code, []) # âœ… íŒŒì‹±ëœ ì„±ë¶„ ì •ë³´ ì¶”ê°€
                }
            
            if row[6]: # ì„±ë¶„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                products_dict[product_code]["supplement_facts"].append({
                    "name": row[6],
                    "amount": float(row[7]) if row[7] else 0.0,
                    "unit": row[8]
                })

        return list(products_dict.values())

# 2. FAISS ì¸ë±ìŠ¤ ìƒì„±
def build_faiss_index():
    print("ğŸ“¦ DBì—ì„œ ì œí’ˆ ì •ë³´ ë¡œë”© ì¤‘...")
    products = load_supplements_from_db()
    documents = []

    for product in products:
        text = f"{product['title']} {product['description']}"  # title + description
        # âœ… ì „ì²´ ì œí’ˆ ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        documents.append(Document(page_content=text, metadata=product))

    print(f"ğŸ§  {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ì„ë² ë”© ì¤‘...")

    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(documents, embeddings)

    # âœ… ì•ˆì „í•˜ê²Œ ì €ì¥ (pickle ì‚¬ìš© âŒ)
    vectorstore.save_local("faiss_index")
    print("âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: faiss_index/")

# 3. FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜
def load_faiss_index():
    embeddings = OpenAIEmbeddings()
    return FAISS.load_local("faiss_index", embeddings)

# âœ… ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if __name__ == "__main__":
    build_faiss_index()