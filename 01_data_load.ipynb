{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a349863b",
   "metadata": {},
   "source": [
    "# ë°ì´í„° êµ¬ì¡° ì´í•´ & SQL ìŠ¤í‚¤ë§ˆ ì„¤ê³„\n",
    "- JSON ë°ì´í„° ë¡œë“œ ë° ì»¬ëŸ¼ í™•ì¸ (pandas)\n",
    "- ê²°ì¸¡ì¹˜Â·ì¤‘ë³µ ë°ì´í„° í™•ì¸/ì •ì œ\n",
    "- SQL DB ìŠ¤í‚¤ë§ˆ ì„¤ê³„ (Supplements, Ingredients, Supplement_Ingredients, Symptoms_Ingredients)â€¢ ì¦ìƒâ€“ì„±ë¶„ ë§¤í•‘ í…Œì´ë¸” ì´ˆì•ˆ ì‘ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1689c",
   "metadata": {},
   "source": [
    "- json íŒŒì¼ ë°ì´í„° ê°œìˆ˜: 1241ê°œ, 23ì—´ ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d51a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) ë¡œë“œ\n",
    "fp = '/Users/gim-yujin/Desktop/pjt_personal_agent/ì˜ì–‘ì†Œ ë°ì´í„°/iherb_data_uk_data_2022_12.json'\n",
    "df = pd.read_json(fp, orient='records')   # íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ of dicts ì—¬ì•¼ ì •ìƒ\n",
    "# 2) ì „ì²´ ì»¬ëŸ¼ í™•ì¸\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "# 3) ìƒ˜í”Œ í™•ì¸\n",
    "display(df.head())\n",
    "# 4) ê¸°ë³¸ íƒ€ì… ì •ë¦¬\n",
    "df['scraped_at'] = pd.to_datetime(df['scraped_at'], dayfirst=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a430d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##ì»¬ëŸ¼ëª… ëª©ë¡\")\n",
    "print(df.columns)\n",
    "print(\"-\" * 50)\n",
    "# ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜ í™•ì¸ \n",
    "print(\"##ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜ í™•ì¸(ê³µë°± ë¬¸ìì—´ì´ ê²°ì¸¡ì¹˜ë¡œ í•©ì‚°ì´ ì•ˆë˜ì–´ ëª¨ë‘ 0ìœ¼ë¡œ í‘œê¸°ë¨)\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc363c",
   "metadata": {},
   "source": [
    "### ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "- ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ë° ê°œìˆ˜\n",
    "- Category 2            4\n",
    "- Category 3          869\n",
    "- ingredients          61\n",
    "- Supplement Facts    530 (ì¶”í›„ì— ì„±ë¶„ì„ ì°¸ê³ í•˜ì—¬ ì±„ì›Œ ë„£ì„ ì˜ˆì •, ë³´ì¶©ì •ë³´(ì˜ì–‘ì„±ë¶„))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ì„ íƒ) ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´ í•œ ë²ˆì— ì ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "print(\"\\n## ì „ì²´ ë°ì´í„°ì˜ ì‹¤ì œ ê²°ì¸¡ì¹˜ ìˆ˜\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ê° ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜ë¥¼ ê³„ì‚°\n",
    "missing_values = df.isnull().sum()\n",
    "#  ê²°ì¸¡ì¹˜ ê°œìˆ˜ê°€ 0ë³´ë‹¤ í° ì»¬ëŸ¼ë“¤ë§Œ í•„í„°ë§í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(\"## ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ë° ê°œìˆ˜\")\n",
    "if columns_with_missing_values.empty:\n",
    "    print(\"ëª¨ë“  ì»¬ëŸ¼ì˜ ë°ì´í„°ê°€ ì±„ì›Œì ¸ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4081542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì„ íƒ ì¶œë ¥ í™•ì¸ \n",
    "\n",
    "df_missing = df[columns_with_missing_values.index]\n",
    "print(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6827246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_with_missing_values.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6230bf",
   "metadata": {},
   "source": [
    "### ì¤‘ë³µ ì œê±° "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98231d0a",
   "metadata": {},
   "source": [
    "- unique_id ê¸°ì¤€(0)\n",
    "- Pid, title ê¸°ì¤€(0)\n",
    "- ì¤‘ë³µë˜ëŠ” ì•„ì´í…œì€ ì—†ìŒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75738431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ë³µ ì œê±° (uniqe_id ê¸°ì¤€ìœ¼ë¡œëŠ” ì¤‘ë³µ ì—†ìŒ.)\n",
    "df = df.drop_duplicates(subset=['uniq_id'])  \n",
    "# uniq_idê°€ ìˆìœ¼ë©´ ì•ˆì „\n",
    "df.drop_duplicates(subset=['Pid','Title'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86011d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Pid','Title']) #ì—¬ê¸°ë„ ì¤‘ë³µì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'] = df['Price'].astype(str)\n",
    "# price >> ë¬¸ìì—´ë¡œ ê³µë°±/ ì‰¼í‘œ ì œê³ í›„ float\n",
    "df['Price'] = df['Price'].str.replace(',', '').str.strip()\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb30a6",
   "metadata": {},
   "source": [
    "### ë¶ˆí•„ìš”í•œ ë ˆì½”ë“œ í•„í„°ë§ \n",
    "- ì¹´í…Œê³ ë¦¬ 1, 2 ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ í•„í„°ë§ í•œ ê²°ê³¼, í•´ë‹¹ ë°ì´í„°ì…‹ì—ì„œ ì˜ì–‘ì œì™€ ê´€ë ¨ëœ ìƒí’ˆ ê°œìˆ˜ëŠ” 1221->325 ê°œë¡œ ê°ì†Œí•¨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## í™”ì¥í’ˆ/ ìƒ´í‘¸/ ì‹í’ˆ/ ë² ì´ë¹„ ìš©í’ˆ ë“± í•„í„°ë§ \n",
    "non_supp_cats = ['Shampoo','Foundation','Face Wash','Utensils','Diapers']  # ì˜ˆì‹œ\n",
    "df = df[~df['Category 2'].isin(non_supp_cats)]\n",
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Category 1' ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ ê°’ ì¶œë ¥\n",
    "print(\"Category 1ì˜ ê³ ìœ ê°’:\", df['Category 1'].unique())\n",
    "\n",
    "# 'Category 2' ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ ê°’ ì¶œë ¥\n",
    "print(\"Category 2ì˜ ê³ ìœ ê°’:\", df['Category 2'].unique())\n",
    "\n",
    "# 'Category 3' ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ ê°’ ì¶œë ¥\n",
    "print(\"Category 3ì˜ ê³ ìœ ê°’:\", df['Category 3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í‚¤ì›Œë“œ(supp_keywords)\n",
    "\n",
    "supp_keywords = [\n",
    "    # ë¹„íƒ€ë¯¼Â·ë¯¸ë„¤ë„\n",
    "    'vitamin', 'multivitamin', 'multimineral', 'b1', 'b2', 'b3', 'b6',\n",
    "    'b12', 'c', 'd', 'e', 'k', 'folic acid', 'niacin', 'biotin',\n",
    "    'calcium', 'magnesium', 'zinc', 'iron', 'selenium', 'potassium',\n",
    "    'iodine', 'trace minerals',\n",
    "\n",
    "    # ì˜¤ë©”ê°€ & í•„ìˆ˜ì§€ë°©ì‚°\n",
    "    'omega', 'fish oil', 'krill oil', 'cod liver oil',\n",
    "    'efa', 'dha', 'epa',\n",
    "\n",
    "    # í—ˆë¸ŒÂ·ì‹ë¬¼ ì¶”ì¶œë¬¼\n",
    "    'herb', 'herbal', 'ashwagandha', 'ginseng', 'echinacea', 'turmeric',\n",
    "    'curcumin', 'milk thistle', 'rhodiola', 'elderberry', 'boswellia',\n",
    "    'sambucus', 'hawthorn', 'garlic', 'ginger', 'licorice', 'oregano',\n",
    "    'passion flower', 'valerian', 'chamomile', 'nettle', 'schisandra',\n",
    "    'astragalus',\n",
    "\n",
    "    # ì•„ë¯¸ë…¸ì‚°Â·ë‹¨ë°±ì§ˆ\n",
    "    'amino', 'amino acid', 'l-',   # L-Arginine, L-Tyrosine ë“± ì•ì— L-ì´ ë¶™ìŒ\n",
    "    'protein', 'collagen', 'peptide',\n",
    "\n",
    "    # í”„ë¡œë°”ì´ì˜¤í‹±/ì†Œí™”\n",
    "    'probiotic', 'prebiotic', 'lactobacillus', 'bifidus',\n",
    "    'digestive enzymes', 'enzyme',\n",
    "\n",
    "    # í•­ì‚°í™”Â·ê¸°íƒ€ ë³´ì¡°ì„±ë¶„\n",
    "    'coq10', 'ubiquinol', 'alpha lipoic acid', 'resveratrol',\n",
    "    'pycnogenol', 'glutathione', 'chlorophyll', 'spirulina',\n",
    "    'chlorella', 'maca', 'bee pollen', 'royal jelly',\n",
    "\n",
    "    # íŠ¹ìˆ˜ ëª©ì  í¬ë®¬ëŸ¬\n",
    "    'immune', 'immune support', 'energy formula', 'sleep formula',\n",
    "    'cognitive', 'memory', 'joint', 'bone', 'liver', 'thyroid',\n",
    "    'blood support', 'heart support', 'detox', 'women\\'s health',\n",
    "    'men\\'s health', 'prenatal', 'post-natal',\n",
    "    'sports supplement', 'workout', 'weight management', 'fat burner',\n",
    "\n",
    "    # í˜•íƒœÂ·ì¼ë°˜ëª…\n",
    "    'supplement', 'dietary', 'nutrition', 'nutrient',\n",
    "    'superfood', 'greens', 'superfood blend'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_supplement_row(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return any(re.search(rf\"\\b{k}\\b\", cats) for k in supp_keywords)\n",
    "\n",
    "df_supp = df[df.apply(is_supplement_row, axis=1)].copy()\n",
    "\n",
    "print(f\"í•„í„° ì „ {len(df)} â†’ í•„í„° í›„ {len(df_supp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939af01",
   "metadata": {},
   "source": [
    "### ì œëŒ€ë¡œ í•„í„°ë§ ë˜ì—ˆëŠ”ì§€ í™•ì¸ ì‘ì—…\n",
    "- ë©€í‹°ë¹„íƒ€ë¯¼ê³¼, ë¹„íƒ€ë¯¼ êµ¬ë¶„í•˜ì—¬ ë†“ì•˜ëŠ”ì§€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1ï¸âƒ£ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ì–‘ì œ í•„í„°\n",
    "def is_supplement_row(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return any(re.search(rf\"\\b{k}\\b\", cats) for k in supp_keywords)\n",
    "\n",
    "df_supp = df[df.apply(is_supplement_row, axis=1)].copy()\n",
    "\n",
    "# 2ï¸âƒ£ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œê±° (í˜„ì¬ëŠ” K-Beauty í•˜ë‚˜ì§€ë§Œ í™•ì¥ ê°€ëŠ¥)\n",
    "black_keywords = ['k-beauty']\n",
    "def not_blacklisted(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 1', '')).lower(),\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return not any(bk in cats for bk in black_keywords)\n",
    "\n",
    "df_supp = df_supp[df_supp.apply(not_blacklisted, axis=1)].copy()\n",
    "\n",
    "print(f\"ìµœì¢… í•„í„° í›„ í–‰ ìˆ˜ : {len(df_supp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ ë¬´ì‘ìœ„ 100ê±´ ì¶”ì¶œ (ì¤‘ë³µ ì—†ì´)\n",
    "sample_100 = df_supp.sample(n=100, random_state=42)  # random_stateëŠ” ì¬í˜„ì„±\n",
    "\n",
    "# 4ï¸âƒ£ ê²€í† ì— ìœ ìš©í•œ ì»¬ëŸ¼ë§Œ ë³´ê¸°\n",
    "cols_to_check = ['Title', 'Category 1', 'Category 2', 'Category 3', 'Description']\n",
    "print(sample_100[cols_to_check].to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5875d",
   "metadata": {},
   "source": [
    "### â€œíŒŒì‹±(parsing)â€: ë¬¸ìì—´(ì˜ˆ: Supplement Facts í…ìŠ¤íŠ¸) ì•ˆì—ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì •ë³´(ì„±ë¶„ëª…, ìš©ëŸ‰, ë‹¨ìœ„ ë“±)ë¥¼ ê·œì¹™ì ìœ¼ë¡œ ë½‘ì•„ë‚´ëŠ” ì‘ì—…\n",
    "\n",
    "- 1.\tparse_supplement_facts()\n",
    "â†’ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ì½ê³  ì •ê·œì‹ìœ¼ë¡œ [ì„±ë¶„, ìˆ˜ì¹˜, ë‹¨ìœ„] ì¶”ì¶œ.\n",
    "- 2.\tparse_and_flag()\n",
    "â†’ ì „ì²´ DataFrameì— ì ìš©, parsed_ingredientsì™€ parse_error ì»¬ëŸ¼ ì¶”ê°€.\n",
    "- 3.\tìˆ˜ë™ ê²€í† \n",
    "â†’ parse_error=Trueì¸ ë ˆì½”ë“œë§Œ CSVë¡œ ë‚´ë³´ë‚´ì–´ ì§ì ‘ í™•ì¸Â·ìˆ˜ì •.\n",
    "--- \n",
    "- df_supp_checked\n",
    "\n",
    "- parsed_ingredients: íŒŒì‹± ì„±ê³µ ì‹œ [{'name':â€¦, 'amount':â€¦, 'unit':â€¦}, â€¦] ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- parse_error: True(ì‹¤íŒ¨) / False(ì„±ê³µ)\n",
    "\n",
    "- supplement_parse_errors.csv\n",
    "\n",
    "ì‚¬ëŒì´ ì§ì ‘ ì‚´í´ë³´ê³  ì •ê·œì‹ ë³´ì™„ì´ë‚˜ ë°ì´í„° ìˆ˜ë™ ì…ë ¥ì´ í•„ìš”í•œ ìƒí’ˆ ëª©ë¡.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pattern = r'(?i)' + '|'.join([re.escape(k) for k in supp_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_supplement_facts(text):\n",
    "    \"\"\"\n",
    "    Supplement Facts ë¬¸ìì—´ì—ì„œ\n",
    "    [ì„±ë¶„ëª…, ìˆ˜ì¹˜, ë‹¨ìœ„] ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return results  # ë¹ˆ ê°’ì´ë©´ ë°”ë¡œ ì‹¤íŒ¨\n",
    "    \n",
    "    # ì˜ˆ) \"Vitamin C 500 mg\", \"Magnesium (as oxide) 250 mg\"\n",
    "    pattern = r'([A-Za-z0-9\\-\\(\\) /]+?)\\s+([\\d.,]+)\\s*(mg|mcg|Âµg|g|iu|IU)'\n",
    "    \n",
    "    for line in text.splitlines():\n",
    "        m = re.search(pattern, line)\n",
    "        if m:\n",
    "            name = m.group(1).strip()\n",
    "            amount = float(m.group(2).replace(',', ''))\n",
    "            unit = m.group(3).lower()\n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'amount': amount,\n",
    "                'unit': unit,\n",
    "                'raw_line': line.strip()\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_flag_supp(df_supp):\n",
    "    parsed_results = []\n",
    "    parse_error_flags = []\n",
    "\n",
    "    for text in df_supp['Supplement Facts']:\n",
    "        parsed = parse_supplement_facts(text)\n",
    "        parsed_results.append(parsed)\n",
    "        # íŒŒì‹± ê²°ê³¼ê°€ ì—†ìœ¼ë©´ True â†’ ì‹¤íŒ¨\n",
    "        parse_error_flags.append(len(parsed) == 0)\n",
    "\n",
    "    df_supp_checked = df_supp.copy()\n",
    "    df_supp_checked['parsed_ingredients'] = parsed_results\n",
    "    df_supp_checked['parse_error'] = parse_error_flags\n",
    "    return df_supp_checked\n",
    "\n",
    "# âœ… ì‹¤í–‰\n",
    "df_supp_checked = parse_and_flag_supp(df_supp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_supp_checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# íŒŒì‹± ì‹¤íŒ¨ ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "df_supp_errors = df_supp_checked[df_supp_checked['parse_error']]\n",
    "\n",
    "# ì£¼ìš” ì»¬ëŸ¼ë§Œ ì €ì¥\n",
    "cols_to_review = ['Title', 'Category 2', 'Category 3', 'Supplement Facts']\n",
    "df_supp_errors[cols_to_review].to_csv('supplement_parse_errors.csv', index=False)\n",
    "\n",
    "print(f\"íŒŒì‹± ì‹¤íŒ¨ ë ˆì½”ë“œ ìˆ˜: {len(df_supp_errors)}\")\n",
    "print(\"ìˆ˜ë™ ê²€í†  íŒŒì¼: supplement_parse_errors.csv ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0937b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì‹± ì‹¤íŒ¨ ë ˆì½”ë“œ ìˆ˜: 198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category 2</th>\n",
       "      <th>Category 3</th>\n",
       "      <th>Supplement Facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MediNatura, WellMind Calming Day/Night, 100 Ta...</td>\n",
       "      <td>Homeopathy Formulas</td>\n",
       "      <td>Cognitive &amp; Memory Formulas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natrol, B-Complex, Fast Dissolve, Coconut, 90 ...</td>\n",
       "      <td>Vitamin B Complex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplement FactsServing Size: 1 TabletServings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NOW Foods, Glycine, Pure Powder, 1 lb (454 g)</td>\n",
       "      <td>L-Glycine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nSupplement Facts\\n\\n\\nServing Size: 3/4 Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Nature's Bounty, Selenium, 200 mcg, 100 Tablets</td>\n",
       "      <td>Selenium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplement FactsServing Size:Â 1 TabletAmount P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dr. Mercola, Zinc plus Selenium, 30 Capsules</td>\n",
       "      <td>Zinc</td>\n",
       "      <td>Selenium</td>\n",
       "      <td>Supplement FactsServing Size: 1 CapsuleServing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Zand, Echinacea Zinc, Very Cherry, 80 Throat L...</td>\n",
       "      <td>Zinc</td>\n",
       "      <td>Sore Throat &amp; Cough Lozenges</td>\n",
       "      <td>Supplement FactsServing Size: 1 lozenge (3.8 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Harney &amp; Sons, Paris Tea, 1 lb</td>\n",
       "      <td>Black Tea</td>\n",
       "      <td>Herbal Tea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Crystal Star, Liver Renew, 90 Vegetarian Capsules</td>\n",
       "      <td>Liver Formulas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplement FactsServing Size:Â 2 capsulesServin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Superior Source, Methylcobalamin B-12, B-6 &amp; F...</td>\n",
       "      <td>Vitamin B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplement FactsServing Size: 1 MicroLingualÂ® ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Life Extension, Standardized Cistanche, 30 Veg...</td>\n",
       "      <td>Herbs</td>\n",
       "      <td>Immune Formulas</td>\n",
       "      <td>Supplement FactsServing Size: 1 Vegetarian Cap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title           Category 2  \\\n",
       "0   MediNatura, WellMind Calming Day/Night, 100 Ta...  Homeopathy Formulas   \n",
       "3   Natrol, B-Complex, Fast Dissolve, Coconut, 90 ...    Vitamin B Complex   \n",
       "24      NOW Foods, Glycine, Pure Powder, 1 lb (454 g)            L-Glycine   \n",
       "44    Nature's Bounty, Selenium, 200 mcg, 100 Tablets             Selenium   \n",
       "45       Dr. Mercola, Zinc plus Selenium, 30 Capsules                 Zinc   \n",
       "48  Zand, Echinacea Zinc, Very Cherry, 80 Throat L...                 Zinc   \n",
       "56                    Harney & Sons, Paris Tea, 1 lb             Black Tea   \n",
       "58  Crystal Star, Liver Renew, 90 Vegetarian Capsules       Liver Formulas   \n",
       "59  Superior Source, Methylcobalamin B-12, B-6 & F...            Vitamin B   \n",
       "61  Life Extension, Standardized Cistanche, 30 Veg...                Herbs   \n",
       "\n",
       "                      Category 3  \\\n",
       "0    Cognitive & Memory Formulas   \n",
       "3                            NaN   \n",
       "24                           NaN   \n",
       "44                           NaN   \n",
       "45                      Selenium   \n",
       "48  Sore Throat & Cough Lozenges   \n",
       "56                    Herbal Tea   \n",
       "58                           NaN   \n",
       "59                           NaN   \n",
       "61               Immune Formulas   \n",
       "\n",
       "                                     Supplement Facts  \n",
       "0                                                 NaN  \n",
       "3   Supplement FactsServing Size: 1 TabletServings...  \n",
       "24  \\n\\nSupplement Facts\\n\\n\\nServing Size: 3/4 Le...  \n",
       "44  Supplement FactsServing Size:Â 1 TabletAmount P...  \n",
       "45  Supplement FactsServing Size: 1 CapsuleServing...  \n",
       "48  Supplement FactsServing Size: 1 lozenge (3.8 g...  \n",
       "56                                                NaN  \n",
       "58  Supplement FactsServing Size:Â 2 capsulesServin...  \n",
       "59  Supplement FactsServing Size: 1 MicroLingualÂ® ...  \n",
       "61  Supplement FactsServing Size: 1 Vegetarian Cap...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supp_errors = df_supp_checked[df_supp_checked['parse_error']]\n",
    "print(\"íŒŒì‹± ì‹¤íŒ¨ ë ˆì½”ë“œ ìˆ˜:\", len(df_supp_errors))\n",
    "df_supp_errors[['Title','Category 2','Category 3','Supplement Facts']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5998bd",
   "metadata": {},
   "source": [
    "### íŒŒì‹± ì‹¤íŒ¨ ë ˆì½”ë“œ ì²˜ë¦¬ \n",
    "- HTML íƒœê·¸ ì œê±°\n",
    "\n",
    "- Proprietary / Matrix / Blend ê°ì§€\n",
    "\n",
    "- ë‹¤ì¤‘ %DV í•­ëª© íƒì§€\n",
    "\n",
    "- Serving Size, Amount Per Serving ê¸°ë°˜ êµ¬ì¡°ì„± ì—¬ë¶€ íŒë‹¨\n",
    "\n",
    "ê²°ê³¼: parsed, ë˜ëŠ” ì‹¤íŒ¨í•œ ê²½ìš° ì‹¤íŒ¨ ì‚¬ìœ  ì½”ë“œ ë¦¬í„´ -->\n",
    "1.\të‹¤ì–‘í•œ ì¤„ë°”ê¿ˆ (\\n, \\r\\n) í˜¹ì€ ê³µë°±ì„ ì œê±°í•˜ì—¬ ì¼ê´€ì„± ìˆê²Œ ì²˜ë¦¬\n",
    "2.\tServing Size, Amount Per Serving, % Daily Value ë“± í•µì‹¬ í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”\n",
    "3.\tì˜ì–‘ì†Œ ì •ë³´ ë¸”ë¡ì„ ì •í™•íˆ ì¶”ì¶œ\n",
    "4.\tMarkdown ë˜ëŠ” HTML íƒœê·¸, ê¸°í˜¸ (â€ , â€¡) ì œê±°\n",
    "5.\tê³µë€ ë˜ëŠ” ë¹„ì •ìƒ ì¼€ì´ìŠ¤ì— ëŒ€í•´ ì•ˆì „í•˜ê²Œ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5523960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"supplement_parse_errors.csv\")\n",
    "\n",
    "# 2. ì‹¤íŒ¨ ì´ìœ  íŒë³„ í•¨ìˆ˜\n",
    "def classify_fail_reason(row):\n",
    "    fact = str(row.get(\"Supplement Facts\", \"\")).strip().lower()\n",
    "\n",
    "    if not fact or fact == \"nan\":\n",
    "        return \"missing_fact\"\n",
    "\n",
    "    if re.search(r\"(<br>|\\\\n|\\\\r|^\\s+|\\n\\s*\\n)\", fact):\n",
    "        return \"html_formatting\"\n",
    "\n",
    "    if re.search(r\"proprietary|herbal blend|extract|complex\", fact):\n",
    "        return \"proprietary_blend\"\n",
    "\n",
    "    if re.search(r\"%\\s*(dv|daily value)[^%]+%.*(child|children|adults|1-3|4+)\", fact):\n",
    "        return \"multi_dv\"\n",
    "\n",
    "    if \"serving size\" in fact and not re.search(r\"amount per serving|% daily value|% dv\", fact):\n",
    "        return \"unstructured\"\n",
    "\n",
    "    return \"other\"\n",
    "\n",
    "# 3. ì ìš©\n",
    "df[\"fail_reason\"] = df.apply(classify_fail_reason, axis=1)\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸ (ìƒìœ„ 10ê°œ)\n",
    "print(df[[\"Title\", \"fail_reason\"]].head(30))\n",
    "\n",
    "# 5. ì €ì¥ (ì„ íƒ ì‚¬í•­)\n",
    "df.to_csv(\"classified_parse_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42037b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³´ì™„ëœ íŒŒì‹± í•¨ìˆ˜(í…ìŠ¤íŠ¸ ê¸°ë°˜ì´ì§€ë§Œ ê·œì¹™ì ìœ¼ë¡œ ë‚˜ì—´ëœ ì„±ë¶„ ì •ë³´ ë½‘ê¸°)\n",
    "\n",
    "def parse_supplement_facts(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    # í•µì‹¬ í‚¤ì›Œë“œë¡œ ì‹œì‘ì  ì¡ê¸°\n",
    "    start_keywords = ['Supplement Facts', 'Serving Size']\n",
    "    start_index = -1\n",
    "    for keyword in start_keywords:\n",
    "        if keyword in cleaned:\n",
    "            start_index = cleaned.find(keyword)\n",
    "            break\n",
    "\n",
    "    if start_index == -1:\n",
    "        return {\"status\": \"fail\", \"reason\": \"í•µì‹¬ í‚¤ì›Œë“œ ì—†ìŒ\", \"data\": None}\n",
    "\n",
    "    # ì¤„ë°”ê¿ˆ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°\n",
    "    block = cleaned[start_index:]\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', block)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # ë‹¤ì–‘í•œ ë‹¨ìœ„ í¬í•¨ (ë¹„í‘œì¤€ ë‹¨ìœ„ ëŒ€ì‘ í¬í•¨)\n",
    "    unit_pattern = r'mg|mcg|Âµg|g|iu|IU|ALU|HUT|FCCFIP|DPÂ°|XU|GalU|AGU|CFU|DPPU|SU|CU|Endo-PGU|HCU|FIP|mg\\*|IU\\*|g\\*'\n",
    "    \n",
    "    # ì„±ë¶„ ì¶”ì¶œ: \"Vitamin C 500 mg\", \"Lactase 9500 ALU\", \"CoQ10 200 mg\"\n",
    "    pattern = rf'([A-Za-z0-9Â®,\\-\\(\\)\\'\\\"\\+/\\. ]{{2,}}?)\\s+([\\d,\\.]+)\\s*({unit_pattern})?'\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, value, unit in matches:\n",
    "        name_clean = name.strip().replace(\":\", \"\").replace(\"â€ \", \"\")\n",
    "        amount = value.replace(\",\", \"\")\n",
    "        nutrients.append({\n",
    "            \"name\": name_clean,\n",
    "            \"amount\": amount,\n",
    "            \"unit\": unit or \"\"\n",
    "        })\n",
    "\n",
    "    return {\"status\": \"success\", \"count\": len(nutrients), \"data\": nutrients}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cda4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'count': 1, 'data': [{'name': '1 Tablet Amount Per Serving Daily Value Vitamin C (as Ascorbic Acid) 500 mg 833 Zinc (as Zinc Gluconate) 15 mg', 'amount': '136', 'unit': ''}]}\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "Supplement Facts\n",
    "Serving Size: 1 Tablet\n",
    "Amount Per Serving % Daily Value\n",
    "Vitamin C (as Ascorbic Acid) 500 mg 833%\n",
    "Zinc (as Zinc Gluconate) 15 mg 136%\n",
    "\"\"\"\n",
    "\n",
    "result = parse_supplement_facts(example_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138aa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparse_failed(df_checked):\n",
    "    reparsed = []\n",
    "    reasons = []\n",
    "\n",
    "    for idx, row in df_checked.iterrows():\n",
    "        if not row['parse_error']:\n",
    "            reparsed.append(row['parsed_ingredients'])\n",
    "            reasons.append(\"ì •ìƒ íŒŒì‹±\")\n",
    "        else:\n",
    "            result = parse_supplement_facts_v3(row['Supplement Facts'])\n",
    "            if result[\"status\"] == \"success\":\n",
    "                reparsed.append(result['data'])\n",
    "                reasons.append(\"ë³´ì™„ íŒŒì‹± ì„±ê³µ\")\n",
    "            else:\n",
    "                reparsed.append(None)\n",
    "                reasons.append(result['reason'])\n",
    "\n",
    "    df_checked['parsed_final'] = reparsed\n",
    "    df_checked['fail_reason_final'] = reasons\n",
    "    df_checked['final_parse_error'] = df_checked['parsed_final'].isnull()\n",
    "    return df_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9462f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë³´ì™„ëœ íŒŒì‹± ì´í›„ ì‹¤íŒ¨ ì‚¬ìœ  í†µê³„:\n",
      " fail_reason_final\n",
      "ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨       93\n",
      "ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤íŒ¨ ì‚¬ìœ ë³„ ê°œìˆ˜\n",
    "fail_summary = df_final_errors['fail_reason_final'].value_counts()\n",
    "print(\"ğŸ“Œ ë³´ì™„ëœ íŒŒì‹± ì´í›„ ì‹¤íŒ¨ ì‚¬ìœ  í†µê³„:\\n\", fail_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29721ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ìµœì¢… ë³´ì™„ìš© íŒŒì‹± í•¨ìˆ˜ ë§Œë“¤ê¸° \n",
    "def parse_supplement_facts_flexible(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "    block = text.strip()\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', block)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # íŒ¨í„´: ì„±ë¶„ëª… (value) (ë‹¨ìœ„) â†’ ë‹¨ìœ„ ìƒëµë„ í—ˆìš©\n",
    "    pattern = r'([A-Za-z0-9 \\-\\(\\)\\[\\]/]+?)\\s+([\\d,\\.]+)\\s*(mg|mcg|g|IU|iu|Âµg|mcg|ml|capsules|tablets|softgels|veggie capsules)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    parsed = []\n",
    "    for name, amount, unit in matches:\n",
    "        parsed.append({\n",
    "            \"name\": name.strip(),\n",
    "            \"amount\": amount.strip(),\n",
    "            \"unit\": (unit or \"\").lower()\n",
    "        })\n",
    "\n",
    "    return {\"status\": \"success\", \"count\": len(parsed), \"data\": parsed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ„ì˜ í•¨ìˆ˜ë¥¼ í™œìš©í•´ì„œ ì¬íŒŒì‹± ì‹¤í–‰ \n",
    "\n",
    "def apply_final_flexible_parsing(df):\n",
    "    results = []\n",
    "    errors = []\n",
    "    reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        res = parse_supplement_facts_flexible(text)\n",
    "        results.append(res)\n",
    "        errors.append(res['status'] == 'fail')\n",
    "        reasons.append(res['reason'] if res['status'] == 'fail' else '')\n",
    "\n",
    "    df = df.copy()\n",
    "    df['parse_result_final2'] = results\n",
    "    df['parse_error_final2'] = errors\n",
    "    df['fail_reason_final2'] = reasons\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "03f89810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ìµœì¢… ë³´ì™„ íŒŒì‹± ì´í›„ ì‹¤íŒ¨ ì‚¬ìœ :\n",
      " fail_reason_final2\n",
      "ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨       93\n",
      "ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì ìš©\n",
    "df_final2 = apply_final_flexible_parsing(df_final_errors)\n",
    "\n",
    "# ì—¬ì „íˆ ì‹¤íŒ¨í•œ ë°ì´í„°\n",
    "df_final2_errors = df_final2[df_final2['parse_error_final2']]\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½\n",
    "fail_summary2 = df_final2_errors['fail_reason_final2'].value_counts()\n",
    "print(\"ğŸ“Œ ìµœì¢… ë³´ì™„ íŒŒì‹± ì´í›„ ì‹¤íŒ¨ ì‚¬ìœ :\\n\", fail_summary2)\n",
    "\n",
    "# ìˆ˜ë™ ê²€í† ìš© ì €ì¥\n",
    "df_final2_errors[['Title', 'Category 2', 'Category 3', 'Supplement Facts']].to_csv('supplement_parse_errors_final2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1f9a4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì§„ì§œ ìµœì¢… íŒŒì‹± ë³´ì™„ í•¨ìˆ˜\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_supplement_facts_v3(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    # ì‹œì‘ ì§€ì  ì¶”ì •\n",
    "    start_keywords = ['Supplement Facts', 'Amount Per Serving']\n",
    "    start_index = -1\n",
    "    for keyword in start_keywords:\n",
    "        if keyword in cleaned:\n",
    "            start_index = cleaned.find(keyword)\n",
    "            break\n",
    "\n",
    "    if start_index == -1:\n",
    "        return {\"status\": \"fail\", \"reason\": \"í•µì‹¬ í‚¤ì›Œë“œ ì—†ìŒ\", \"data\": None}\n",
    "\n",
    "    block = cleaned[start_index:]\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', block)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+|â€ â€ ', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # ë‹¤ì–‘í•œ ë‹¨ìœ„ í¬í•¨ (ë¹„í‘œì¤€ ë‹¨ìœ„ ëŒ€ì‘ í¬í•¨)\n",
    "    unit_pattern = r'mg|mcg|Âµg|g|iu|IU|ALU|HUT|FCCFIP|DPÂ°|XU|GalU|AGU|CFU|DPPU|SU|CU|Endo-PGU|HCU|FIP|mg\\*|IU\\*|g\\*'\n",
    "    \n",
    "    # ì„±ë¶„ ì¶”ì¶œ: \"Vitamin C 500 mg\", \"Lactase 9500 ALU\", \"CoQ10 200 mg\"\n",
    "    pattern = rf'([A-Za-z0-9Â®,\\-\\(\\)\\'\\\"\\+/\\. ]{{2,}}?)\\s+([\\d,\\.]+)\\s*({unit_pattern})?'\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, value, unit in matches:\n",
    "        name_clean = name.strip().replace(\":\", \"\").replace(\"â€ \", \"\")\n",
    "        amount = value.replace(\",\", \"\")\n",
    "        nutrients.append({\n",
    "            \"name\": name_clean,\n",
    "            \"amount\": amount,\n",
    "            \"unit\": unit or \"\"\n",
    "        })\n",
    "\n",
    "    return {\"status\": \"success\", \"count\": len(nutrients), \"data\": nutrients}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f85fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì‹¤íŒ¨ ë°ì´í„°ì— ìµœì¢… íŒŒì‹± ì ìš©\n",
    "def reparse_failed(df_checked):\n",
    "    reparsed = []\n",
    "    reasons = []\n",
    "\n",
    "    for idx, row in df_checked.iterrows():\n",
    "        if not row['parse_error']:\n",
    "            reparsed.append(row['parsed_ingredients'])\n",
    "            reasons.append(\"ì •ìƒ íŒŒì‹±\")\n",
    "        else:\n",
    "            result = parse_supplement_facts_v3(row['Supplement Facts'])\n",
    "            if result[\"status\"] == \"success\":\n",
    "                reparsed.append(result['data'])\n",
    "                reasons.append(\"ë³´ì™„ íŒŒì‹± ì„±ê³µ\")\n",
    "            else:\n",
    "                reparsed.append(None)\n",
    "                reasons.append(result['reason'])\n",
    "\n",
    "    df_checked['parsed_final'] = reparsed\n",
    "    df_checked['fail_reason_final'] = reasons\n",
    "    df_checked['final_parse_error'] = df_checked['parsed_final'].isnull()\n",
    "    return df_checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b2fe15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³´ì™„ëœ íŒŒì„œ (V3)ë¥¼ ì ìš©í•œ ìµœì¢… íŒŒì‹± í•¨ìˆ˜\n",
    "def final_parse_supplement(text):\n",
    "    result = parse_supplement_facts_v3(text)\n",
    "    return result\n",
    "\n",
    "def final_flag_parse_error(parse_result):\n",
    "    if isinstance(parse_result, dict) and parse_result.get(\"status\") == \"fail\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def final_get_fail_reason(parse_result):\n",
    "    if isinstance(parse_result, dict) and parse_result.get(\"status\") == \"fail\":\n",
    "        return parse_result.get(\"reason\")\n",
    "    return None\n",
    "\n",
    "# âœ… df_suppëŠ” ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (ë˜ëŠ” ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„)\n",
    "df_final = df_supp.copy()\n",
    "\n",
    "# ìµœì¢… íŒŒì‹± ê²°ê³¼ ì ìš©\n",
    "df_final[\"final_parse_result\"] = df_final[\"Supplement Facts\"].apply(final_parse_supplement)\n",
    "df_final[\"final_parse_error\"] = df_final[\"final_parse_result\"].apply(final_flag_parse_error)\n",
    "df_final[\"fail_reason_final\"] = df_final[\"final_parse_result\"].apply(final_get_fail_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe654b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ìµœì¢… íŒŒì‹± ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ìˆ˜: 105ê°œ\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ì‹¤íŒ¨ ì‚¬ìœ  ë¶„í¬:\n",
      "fail_reason_final\n",
      "ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨       86\n",
      "ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… íŒŒì‹± ì‹¤íŒ¨ ë ˆì½”ë“œ ìˆ˜ ì¶œë ¥\n",
    "num_final_failures = df_final['final_parse_error'].sum()\n",
    "print(f\"âŒ ìµœì¢… íŒŒì‹± ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ìˆ˜: {num_final_failures}ê°œ\")\n",
    "\n",
    "# ì‹¤íŒ¨ ì‚¬ìœ ë³„ ë¶„í¬ë„ í™•ì¸\n",
    "fail_summary = df_final['fail_reason_final'].value_counts()\n",
    "print(\"\\nğŸ“Š íŒŒì‹± ì‹¤íŒ¨ ì‚¬ìœ  ë¶„í¬:\")\n",
    "print(fail_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "80fef30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ supplement_parse_errors_final.csv ì €ì¥ ì™„ë£Œ! ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ìˆ˜: 105ê°œ\n"
     ]
    }
   ],
   "source": [
    "# â—ìµœì¢… íŒŒì‹± ì‹¤íŒ¨í•œ ë ˆì½”ë“œë§Œ ì €ì¥\n",
    "df_final_errors = df_final[df_final['final_parse_error'] == True]\n",
    "\n",
    "# ì£¼ìš” ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•´ì„œ ì €ì¥\n",
    "df_final_errors[['Title', 'Category 2', 'Category 3', 'Supplement Facts']].to_csv(\n",
    "    'supplement_parse_errors_final.csv', index=False\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“ supplement_parse_errors_final.csv ì €ì¥ ì™„ë£Œ! ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ìˆ˜: {len(df_final_errors)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8dde5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ìµœìµœìµœì¢… íŒŒì‹± \n",
    "import re\n",
    "\n",
    "def final_parse_supplement_facts(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "    \n",
    "    # ì „ì²˜ë¦¬\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = re.sub(r'[*â€ â€¡]+', '', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "\n",
    "    # ì£¼ì„ êµ¬ê°„ ì œê±° (Daily Value not established ë“±)\n",
    "    text = re.sub(r'Daily Value.*?established[.]*', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # íŒ¨í„´: ì„±ë¶„ëª… + ìˆ˜ì¹˜ + ë‹¨ìœ„\n",
    "    pattern = r'([A-Za-z0-9Â®,\\-â€™\\'\\\"\\(\\)\\[\\]\\/\\+\\:\\s]+?)\\s+([\\d\\.,]+)\\s*(mcg|Âµg|mg|g|iu|IU|%)'\n",
    "\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    results = []\n",
    "    for name, value, unit in matches:\n",
    "        try:\n",
    "            value = float(value.replace(',', '').strip())\n",
    "        except:\n",
    "            continue\n",
    "        results.append({\n",
    "            'name': name.strip(),\n",
    "            'amount': value,\n",
    "            'unit': unit.lower()\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"count\": len(results),\n",
    "        \"data\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "487099c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'count': 3, 'data': [{'name': 'Daily Value Vitamin C (as Ascorbic Acid)', 'amount': 500.0, 'unit': 'mg'}, {'name': 'Zinc (as Zinc Gluconate)', 'amount': 15.0, 'unit': 'mg'}, {'name': 'Biotin', 'amount': 333.0, 'unit': 'mcg'}]}\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸\n",
    "example = \"\"\"\n",
    "Supplement Facts\n",
    "Serving Size: 1 Tablet\n",
    "Amount Per Serving % Daily Value\n",
    "Vitamin C (as Ascorbic Acid) 500 mg 833%\n",
    "Zinc (as Zinc Gluconate) 15 mg 136%\n",
    "Biotin 333 mcg 1,110%\n",
    "\"\"\"\n",
    "\n",
    "result = final_parse_supplement_facts(example)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7d93943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parse_result'] = df['Supplement Facts'].apply(final_parse_supplement_facts)\n",
    "df['parse_status'] = df['parse_result'].apply(lambda x: x['status'])\n",
    "df['fail_reason'] = df['parse_result'].apply(lambda x: x['reason'] if x['status'] == 'fail' else None)\n",
    "\n",
    "# ì‹¤íŒ¨ ë°ì´í„°ë§Œ ì €ì¥\n",
    "df_errors = df[df['parse_status'] == 'fail']\n",
    "df_errors[['Title', 'Category 2', 'Category 3', 'Supplement Facts', 'fail_reason']].to_csv('supplement_parse_errors_final3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bbcde53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì‹¤íŒ¨ ì‚¬ìœ ë³„ ê°œìˆ˜:\n",
      " fail_reason_final\n",
      "ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨       86\n",
      "ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'fail_reason_final'ì´ ìˆëŠ” ê²½ìš°\n",
    "fail_counts = df_final['fail_reason_final'].value_counts()\n",
    "print(\"ğŸ“Š ì‹¤íŒ¨ ì‚¬ìœ ë³„ ê°œìˆ˜:\\n\", fail_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "996ddc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## íë¦„ ì •ë¦¬ \n",
    "# # 1. ë¨¼ì € í•¨ìˆ˜ ì •ì˜\n",
    "# def parse_supplement_facts_v3(text): ...\n",
    "# def apply_final_parsing(df): ...\n",
    "\n",
    "# # 2. ë°ì´í„°í”„ë ˆì„ì— ì ìš©\n",
    "# df_final = apply_final_parsing(df_failed)  # df_failedëŠ” ì‹¤íŒ¨í•œ ë ˆì½”ë“œ ëª¨ìŒ\n",
    "\n",
    "# # 3. ì‹¤íŒ¨í•œ ê°œìˆ˜ ë° ì´ìœ  í™•ì¸\n",
    "# df_final['fail_reason_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì ˆë§ì ì´ì–´ë„ ê°€ì.. 4ì°¨ ë³´ì™„ íŒŒì‹± í•¨ìˆ˜ \n",
    "\n",
    "import re\n",
    "\n",
    "def parse_supplement_facts_v3(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    cleaned = text.strip()\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', cleaned)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # ë³´ì™„ëœ ì •ê·œì‹: ë‹¨ìœ„ ë‹¤ì–‘í™” + ê´„í˜¸ ì•ˆ ì„±ë¶„ í—ˆìš©\n",
    "    pattern = r'([A-Za-z0-9 \\-â€“Â®â„¢\\(\\)\\[\\],\\'+Â°]+?)\\s+([\\d\\.,]+)\\s*(mcg|mg|g|iu|IU|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\",\n",
    "        \"count\": len(nutrients),\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88ed3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µí•© ì ìš© í•¨ìˆ˜ \n",
    "def apply_final_parsing(df):\n",
    "    parsed_results = []\n",
    "    parse_status = []\n",
    "    fail_reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        result = parse_supplement_facts_v3(text)\n",
    "        parsed_results.append(result['data'])\n",
    "        parse_status.append(result['status'] == 'fail')\n",
    "        fail_reasons.append(result['reason'] if result['status'] == 'fail' else None)\n",
    "\n",
    "    df_result = df.copy()\n",
    "    df_result['final_parsed'] = parsed_results\n",
    "    df_result['final_parse_error'] = parse_status\n",
    "    df_result['fail_reason_final'] = fail_reasons\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "03f748d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ìµœì¢… ì‹¤íŒ¨: 111ê°œ\n"
     ]
    }
   ],
   "source": [
    "# 1ï¸âƒ£ ì´ˆê¸° íŒŒì‹± í›„ ì‹¤íŒ¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "df_failed = df_supp_checked[df_supp_checked['parse_error']]\n",
    "\n",
    "# 2ï¸âƒ£ ë³´ì™„ëœ íŒŒì‹± í•¨ìˆ˜ ì ìš©\n",
    "df_final = apply_final_parsing(df_failed)\n",
    "\n",
    "# 3ï¸âƒ£ ìµœì¢… ì‹¤íŒ¨í•œ ê²ƒ í™•ì¸\n",
    "df_final_errors = df_final[df_final['final_parse_error']]\n",
    "print(f\"âŒ ìµœì¢… ì‹¤íŒ¨: {len(df_final_errors)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895ce54",
   "metadata": {},
   "source": [
    "- í…ìŠ¤ ìì²´ê°€ ë‚œí•´í•˜ê±°ë‚˜, ë³´ì¶©ì œê°€ ì•„ë‹Œ ìƒí’ˆì´ ì„ì—¬ìˆì–´ ìœ„ì˜ ë§ì€ ì‹œë„ì—ì„œ ì‹¤íŒ¨í•œ ê²ƒì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7bda42ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ìµœì¢… ì‹¤íŒ¨ ìˆ˜: 57\n",
      "\n",
      "ğŸ“Š ì‹¤íŒ¨ ì‚¬ìœ  ë¶„í¬:\n",
      "fail_reason_final\n",
      "ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨       56\n",
      "ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: supplement_parse_errors_final_v4.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- ìœ í‹¸/ì •ê·œì‹ ----------\n",
    "UNITS_PATTERN = r\"(mcg|Âµg|mg|g|kg|IU|iu|CFU|DPPU|ALU|HUT|FIP|FCCFIP|SU|XU|AGU|DPÂ°?|CU|PGU|HCU|mEq)\"\n",
    "DENY_HEADER = re.compile(\n",
    "    r'\\b(Serving Size|Servings? Per Container|Amount Per Serving|% ?Daily Value|% ?DV|Daily Value|DV\\b|Calories\\b|'\n",
    "    r'Total Fat\\b|Saturated Fat\\b|Trans Fat\\b|Cholesterol\\b|Sodium\\b|Total Carbohydrate\\b|Dietary Fiber\\b|Total Sugars\\b|'\n",
    "    r'Added Sugars\\b|Protein\\b|Potassium\\b|Calcium\\b|Iron\\b|Vitamin D\\b|Magnesium\\b|Phosphorus\\b|Manganese\\b)\\b',\n",
    "    re.I\n",
    ")\n",
    "\n",
    "SKIP_CATS = [\n",
    "    # ë¹„-ë³´ì¶©ì œë¡œ ê°„ì£¼: íŒŒì‹± ì‹¤íŒ¨ ì¹´ìš´íŠ¸ì—ì„œ ì œì™¸\n",
    "    'tea','herbal tea','peppermint tea','chamomile','black tea',\n",
    "    'serum','serums','beauty','lotion','face','peel','mask','body','skin',\n",
    "    'oil','oils',\n",
    "    'spice','spices','seasoning',\n",
    "    'bar','bars','protein bar','whey protein bars','milk protein bars',\n",
    "    'workout enhancer','workout'\n",
    "]\n",
    "\n",
    "def normalize_panel(text: str) -> str:\n",
    "    s = text if isinstance(text, str) else str(text)\n",
    "    # ìœ ë‹ˆì½”ë“œ ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬\n",
    "    s = s.replace(\"\\xa0\",\" \").replace(\"\\u2009\",\" \").replace(\"\\u202f\",\" \")\n",
    "    s = re.sub(r'[\\r\\t]', ' ', s)\n",
    "    # â€ , â€¡, *, ë¶ˆë¦¿ ì œê±°\n",
    "    s = re.sub(r'[â€ â€¡*â€¢â—]+', '', s)\n",
    "    # ê¸€ì/ê´„í˜¸] ë°”ë¡œ ë’¤ì— ìˆ«ìê°€ ë¶™ì€ ê²½ìš° ê³µë°± ì‚½ì…: \"Niacin250\" -> \"Niacin 250\"\n",
    "    s = re.sub(r'(?<=[A-Za-z\\)\\]])(?=\\d)', ' ', s)\n",
    "    # ë‹¨ìœ„ì™€ ë‹¤ìŒ ìˆ«ì ë¶™ì€ ì¼€ì´ìŠ¤ ê³µë°±: \"mg1,563%\" -> \"mg 1,563%\"\n",
    "    s = re.sub(r'(?i)\\b(mcg|Âµg|mg|g|iu|IU|CFU)(?=\\d)', r'\\1 ', s)\n",
    "    # ë‹¤ì¤‘ ê³µë°± ì •ë¦¬\n",
    "    s = re.sub(r'\\s{2,}', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def parse_line_items(block: str):\n",
    "    items = []\n",
    "\n",
    "    # 1) ê¸°ë³¸ íŒ¨í„´: [ì´ë¦„] [ìˆ˜ì¹˜] [ë‹¨ìœ„]\n",
    "    pat_main = re.compile(\n",
    "        rf\"(?P<name>[A-Za-z][A-Za-z0-9 \\-â€“Â®â„¢\\(\\)\\[\\],\\'\\+Â°/\\.]+?)\\s+\"\n",
    "        rf\"(?P<amount>[\\d][\\d,\\.]*)\\s*\"\n",
    "        rf\"(?P<unit>{UNITS_PATTERN})\\b\"\n",
    "    )\n",
    "\n",
    "    for m in pat_main.finditer(block):\n",
    "        name = m.group('name').strip()\n",
    "        if DENY_HEADER.search(name):\n",
    "            continue\n",
    "        try:\n",
    "            amount = float(m.group('amount').replace(',', ''))\n",
    "            unit = m.group('unit')\n",
    "            items.append({'name': name, 'amount': amount, 'unit': unit})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 2) CFU(ë°±ë§Œ/ì–µ ë‹¨ìœ„) ì¶”ê°€ í¬ì°©: \"(65 Billion CFU)\" ë“±\n",
    "    pat_cfu = re.compile(r\"(?P<amount>[\\d][\\d,\\.]*)\\s*(?P<scale>Billion|Million)\\s*CFU\", re.I)\n",
    "    for m in pat_cfu.finditer(block):\n",
    "        try:\n",
    "            amt = float(m.group('amount').replace(',', ''))\n",
    "            factor = 1e9 if m.group('scale').lower() == 'billion' else 1e6\n",
    "            items.append({'name': 'Probiotic CFU', 'amount': amt*factor, 'unit': 'CFU'})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 3) ì¤‘ë³µ ì œê±°\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for it in items:\n",
    "        key = (it['name'].lower(), it['unit'].lower(), it['amount'])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        uniq.append(it)\n",
    "    return uniq\n",
    "\n",
    "def is_skip_category(cat2, cat3):\n",
    "    cats = ' '.join([c for c in [cat2, cat3] if isinstance(c, str)]).lower()\n",
    "    return any(tok in cats for tok in SKIP_CATS)\n",
    "\n",
    "# ---------- 4ì°¨ ë³´ì™„ íŒŒì„œ ----------\n",
    "def parse_supplement_facts_v4(text: str, cat2=None, cat3=None) -> dict:\n",
    "    # ë¹„-ë³´ì¶©ì œ ì¹´í…Œê³ ë¦¬ë©´ skip ì²˜ë¦¬ (ì‹¤íŒ¨ë¡œ ì„¸ì§€ ì•ŠìŒ)\n",
    "    if is_skip_category(cat2, cat3):\n",
    "        return {\"status\": \"skip\", \"reason\": \"non-supplement category\", \"data\": None}\n",
    "\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    block = normalize_panel(text)\n",
    "\n",
    "    # \"Supplement Facts\" í‚¤ì›Œë“œê°€ ì—†ë”ë¼ë„ ë‹¨ìœ„ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì‹¤íŒ¨\n",
    "    if (\"supplement facts\" not in block.lower()) and (re.search(rf\"\\b{UNITS_PATTERN}\\b\", block, re.I) is None):\n",
    "        return {\"status\": \"fail\", \"reason\": \"í•µì‹¬ í‚¤ì›Œë“œ/ë‹¨ìœ„ ì—†ìŒ\", \"data\": None}\n",
    "\n",
    "    items = parse_line_items(block)\n",
    "    if not items:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    return {\"status\": \"success\", \"count\": len(items), \"data\": items}\n",
    "\n",
    "# ---------- í†µí•© ì ìš© í•¨ìˆ˜ ----------\n",
    "def apply_final_parsing_v2(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    parsed_results, parse_error_flags, fail_reasons = [], [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        res = parse_supplement_facts_v4(\n",
    "            row.get('Supplement Facts', ''),\n",
    "            row.get('Category 2'), row.get('Category 3')\n",
    "        )\n",
    "        parsed_results.append(res.get('data'))\n",
    "        # success/skip ì€ ì˜¤ë¥˜ ì•„ë‹˜\n",
    "        parse_error_flags.append(res['status'] == 'fail')\n",
    "        fail_reasons.append(res.get('reason'))\n",
    "\n",
    "    out = df.copy()\n",
    "    out['final_parsed'] = parsed_results\n",
    "    out['final_parse_error'] = parse_error_flags\n",
    "    out['fail_reason_final'] = fail_reasons\n",
    "    return out\n",
    "\n",
    "# ---------- ì‹¤í–‰ ì˜ˆì‹œ (ë‹¹ì‹ ì˜ ë³€ìˆ˜ëª…ì— ë§ì¶° ê·¸ëŒ€ë¡œ ì‚¬ìš©) ----------\n",
    "# 1) ì´ˆê¸° ì‹¤íŒ¨ë§Œ ì¶”ì¶œ (ì´ë¯¸ ê°€ì§€ê³  ìˆëŠ” df_supp_checked ê¸°ì¤€)\n",
    "df_failed = df_supp_checked[df_supp_checked['parse_error']].copy()\n",
    "\n",
    "# 2) 4ì°¨ ë³´ì™„ íŒŒì‹± ì ìš©\n",
    "df_final_v4 = apply_final_parsing_v2(df_failed)\n",
    "\n",
    "# 3) ìµœì¢… ì‹¤íŒ¨ ê±´ìˆ˜/ì‚¬ìœ  í™•ì¸\n",
    "df_final_v4_errors = df_final_v4[df_final_v4['final_parse_error']]\n",
    "print(f\"âŒ ìµœì¢… ì‹¤íŒ¨ ìˆ˜: {len(df_final_v4_errors)}\")\n",
    "print(\"\\nğŸ“Š ì‹¤íŒ¨ ì‚¬ìœ  ë¶„í¬:\")\n",
    "print(df_final_v4_errors['fail_reason_final'].value_counts(dropna=False))\n",
    "\n",
    "# 4) ì‹¤íŒ¨ ë°ì´í„°ë§Œ CSVë¡œ ì €ì¥ (í˜„ì¬ ì‘ì—… í´ë”ì— ì €ì¥)\n",
    "df_final_v4_errors[['Title','Category 2','Category 3','Supplement Facts','fail_reason_final']].to_csv(\n",
    "    'supplement_parse_errors_final_v4.csv', index=False\n",
    ")\n",
    "print(\"\\nğŸ’¾ ì €ì¥ ì™„ë£Œ: supplement_parse_errors_final_v4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670fb4a",
   "metadata": {},
   "source": [
    "-ë³µì¡í•œ ë¸”ëœë“œë‚˜ í‘œê¸° ë‹¨ìœ„ìƒëµ,ë¶ˆê·œì¹™í•œ ê²½ìš°ëŠ” ì—¬ì „íˆ íŒŒì‹±ì´ ì•ˆëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91af389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ì°¨ ë³´ì™„ íŒŒì‹± ê²°ê³¼ ì´ ì‹¤íŒ¨ 20ê°œë¡œ ì¤„ì–´ë“¦ \n",
    "def parse_supplement_facts_v4(text: str) -> dict:\n",
    "    import re\n",
    "\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', text)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    unit_pattern = r'(mcg|mg|g|iu|IU|CFU|DPPU|FIP|HUT|GalU|AGU|SU|CU|DP|XU|ALU|Î¼g|ml|%)?'\n",
    "    pattern = rf'([A-Za-z0-9Â®â„¢\\(\\)\\[\\],\\-&\\/\\'Â° +]+?)\\s+([\\d\\.,]+)\\s*{unit_pattern}'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\",\n",
    "        \"count\": len(nutrients),\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9f29bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ì°¨ í†µí•© ì ìš© í•¨ìˆ˜ \n",
    "def apply_final_parsing_v4(df):\n",
    "    parsed_results = []\n",
    "    parse_status = []\n",
    "    fail_reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        result = parse_supplement_facts_v4(text)\n",
    "        parsed_results.append(result['data'])\n",
    "        parse_status.append(result['status'] == 'fail')\n",
    "        fail_reasons.append(result['reason'] if result['status'] == 'fail' else None)\n",
    "\n",
    "    df_result = df.copy()\n",
    "    df_result['final_parsed'] = parsed_results\n",
    "    df_result['final_parse_error'] = parse_status\n",
    "    df_result['fail_reason_final'] = fail_reasons\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "61399b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) ì‹¤íŒ¨ ë°ì´í„°ë§Œ CSVë¡œ ì €ì¥ (í˜„ì¬ ì‘ì—… í´ë”ì— ì €ì¥)\n",
    "df_final_v4_errors[['Title','Category 2','Category 3','Supplement Facts','fail_reason_final']].to_csv(\n",
    "    'supplement_parse_errors_final_v4.csv', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "880337bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# âœ… 5ì°¨ ë³´ì™„ íŒŒì‹± í•¨ìˆ˜\n",
    "def parse_supplement_facts_v5(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    # 1ï¸âƒ£ ë¬¸ìì—´ ì „ì²˜ë¦¬\n",
    "    cleaned = text.strip()\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', cleaned)\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+|â™¦|â€¢|â—|â—†|â€¦|â€“|â€”', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # 2ï¸âƒ£ ì •ê·œì‹ - ì„±ë¶„ëª…ì— ê´„í˜¸/ìƒí‘œ í¬í•¨, ë‹¨ìœ„ ë‹¤ì–‘í™”\n",
    "    pattern = r'([A-Za-z0-9 \\-â€“Â®â„¢\\(\\)\\[\\],\\'+Â°]+?)\\s+([\\d\\.,]+)\\s*(mg|mcg|g|IU|iu|billion CFU|CFU|ALU|HUT|XU|DP|SU|CU|FIP|DPPU|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\",\n",
    "        \"count\": len(nutrients),\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }\n",
    "\n",
    "# âœ… í†µí•© ì ìš© í•¨ìˆ˜\n",
    "def apply_final_parsing_v5(df):\n",
    "    parsed_results = []\n",
    "    parse_status = []\n",
    "    fail_reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        result = parse_supplement_facts_v5(text)\n",
    "        parsed_results.append(result['data'])\n",
    "        parse_status.append(result['status'] == 'fail')\n",
    "        fail_reasons.append(result['reason'] if result['status'] == 'fail' else None)\n",
    "\n",
    "    df_result = df.copy()\n",
    "    df_result['final5_parsed'] = parsed_results\n",
    "    df_result['final5_parse_error'] = parse_status\n",
    "    df_result['fail_reason_final5'] = fail_reasons\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "49bdfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ 5ì°¨ íŒŒì‹± í›„ ìµœì¢… ì‹¤íŒ¨ ìˆ˜: 33ê°œ\n",
      "âœ… ìµœì¢… ì‹¤íŒ¨ ë°ì´í„° ì €ì¥ ì™„ë£Œ: supplement_parse_errors_final5.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV ë¡œë“œ\n",
    "df_failed_v4 = pd.read_csv(\"/Users/gim-yujin/Desktop/pjt_personal_agent/supplement_parse_errors_final_v4.csv\")\n",
    "\n",
    "# 5ì°¨ íŒŒì‹± ì ìš©\n",
    "df_final5 = apply_final_parsing_v5(df_failed_v4)\n",
    "\n",
    "# ìµœì¢… ì‹¤íŒ¨ ë°ì´í„° ì¶”ì¶œ\n",
    "df_final5_errors = df_final5[df_final5['final5_parse_error']]\n",
    "\n",
    "# ê°œìˆ˜ í™•ì¸\n",
    "print(f\"âŒ 5ì°¨ íŒŒì‹± í›„ ìµœì¢… ì‹¤íŒ¨ ìˆ˜: {len(df_final5_errors)}ê°œ\")\n",
    "\n",
    "# ì €ì¥\n",
    "df_final5_errors.to_csv(\"supplement_parse_errors_final5.csv\", index=False)\n",
    "print(\"âœ… ìµœì¢… ì‹¤íŒ¨ ë°ì´í„° ì €ì¥ ì™„ë£Œ: supplement_parse_errors_final5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6ì°¨ íŒŒì‹± í•¨ìˆ˜ \n",
    "def parse_supplement_facts_v6(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    cleaned = text.strip()\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', cleaned)\n",
    "    block = re.sub(r'[â€ â€¡*%âˆÂ®â„¢â†’â€¢â™¦â€“â€¢]', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # ê´„í˜¸ ì•ˆ ìˆ«ì+ë‹¨ìœ„ ì œê±° (ì˜ˆ: (400 mg))\n",
    "    block = re.sub(r'\\([^\\)]*\\d+(?:\\.\\d+)?\\s?(mg|mcg|g|IU|iu|%)\\)', '', block)\n",
    "\n",
    "    # Proprietary Blend ì œê±° ë¸”ëŸ­ (ìˆìœ¼ë©´ ë”°ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ì§€ë§Œ ì¼ë‹¨ ì œê±°)\n",
    "    block = re.sub(r'Proprietary Blend.*?(?=\\d+[\\s]*(mg|mcg|g|IU|iu|%|$))', '', block, flags=re.IGNORECASE)\n",
    "\n",
    "    # ìµœì¢… ì •ê·œì‹ (ë‹¨ìœ„ í™•ì¥ í¬í•¨)\n",
    "    pattern = r'([A-Za-z0-9 \\-â€“Â®â„¢\\(\\)\\[\\],\\'Â°+/&Â·:]+?)\\s+([\\d\\.,]+)\\s*(billion CFU|CFU|DPPU|DU|XU|DP|ALU|HUT|SU|CU|FIP|mg|mcg|g|IU|iu|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\",\n",
    "        \"count\": len(nutrients),\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a6bc9ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_86978/2721993828.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed5['final6_parsed'] = parsed6.apply(lambda x: x['data'])\n",
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_86978/2721993828.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed5['final6_parse_error'] = parsed6.apply(lambda x: x['status'] == 'fail')\n",
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_86978/2721993828.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed5['fail_reason_final6'] = parsed6.apply(lambda x: x['reason'] if x['status'] == 'fail' else None)\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤íŒ¨ ë°ì´í„°ì—ì„œë§Œ ì ìš©\n",
    "df_failed5 = df_final5[df_final5['final5_parse_error']]\n",
    "\n",
    "# ì ìš©\n",
    "parsed6 = df_failed5['Supplement Facts'].apply(parse_supplement_facts_v6)\n",
    "df_failed5['final6_parsed'] = parsed6.apply(lambda x: x['data'])\n",
    "df_failed5['final6_parse_error'] = parsed6.apply(lambda x: x['status'] == 'fail')\n",
    "df_failed5['fail_reason_final6'] = parsed6.apply(lambda x: x['reason'] if x['status'] == 'fail' else None)\n",
    "\n",
    "# ë‹¤ì‹œ ë³‘í•©\n",
    "df_final6 = df_final5.copy()\n",
    "df_final6.loc[df_failed5.index, 'final6_parsed'] = df_failed5['final6_parsed']\n",
    "df_final6.loc[df_failed5.index, 'final6_parse_error'] = df_failed5['final6_parse_error']\n",
    "df_final6.loc[df_failed5.index, 'fail_reason_final6'] = df_failed5['fail_reason_final6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "30bf6748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš¨ ìµœì¢… 6ì°¨ íŒŒì‹± ì‹¤íŒ¨ ìˆ˜: 2ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_86978/1184695141.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_fail_final6 = df_final6[df_final6['final6_parse_error'].fillna(False)]\n"
     ]
    }
   ],
   "source": [
    "# NaN ê°’ì„ Falseë¡œ ê°„ì£¼í•˜ë„ë¡ ì²˜ë¦¬\n",
    "df_fail_final6 = df_final6[df_final6['final6_parse_error'].fillna(False)]\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(f\"ğŸš¨ ìµœì¢… 6ì°¨ íŒŒì‹± ì‹¤íŒ¨ ìˆ˜: {len(df_fail_final6)}ê°œ\")\n",
    "\n",
    "# CSV ì €ì¥\n",
    "df_fail_final6.to_csv('supplement_parse_errors_final6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1949bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7ì°¨ íŒŒì‹± í•¨ìˆ˜\n",
    "import re\n",
    "\n",
    "def parse_supplement_facts_v7(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"ê³µë€ ë˜ëŠ” íƒ€ì… ì˜¤ë¥˜\", \"data\": None}\n",
    "\n",
    "    # 1. í…ìŠ¤íŠ¸ ì •ì œ\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', text.strip())\n",
    "    block = re.sub(r'â€ |â€¡|[*]+|[%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block).strip()\n",
    "\n",
    "    # 2. ë¬¸ì+ìˆ«ì ë¶™ì–´ìˆëŠ” ê²½ìš° ê³µë°± ë„£ê¸° (ì˜ˆ: \"VitaminC1000mg\" â†’ \"VitaminC 1000mg\")\n",
    "    block = re.sub(r'([a-zA-Z\\)])(?=\\d)', r'\\1 ', block)\n",
    "\n",
    "    # 3. íŒ¨í„´ ì •ì˜\n",
    "    pattern = r'([A-Za-z0-9 \\-â€“Â®â„¢\\(\\)\\[\\],\\'+Â°]+?)\\s+([\\d\\.,]+)\\s*(mcg|mg|g|iu|IU|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"ì„±ë¶„ ì¶”ì¶œ ì‹¤íŒ¨\",\n",
    "        \"count\": len(nutrients),\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7ecdd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µí•© ì ìš© í•¨ìˆ˜ \n",
    "def apply_final7_parsing(df):\n",
    "    parsed_results = []\n",
    "    parse_status = []\n",
    "    fail_reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        result = parse_supplement_facts_v7(text)\n",
    "        parsed_results.append(result['data'])\n",
    "        parse_status.append(result['status'] == 'fail')\n",
    "        fail_reasons.append(result['reason'] if result['status'] == 'fail' else None)\n",
    "\n",
    "    df_result = df.copy()\n",
    "    df_result['final7_parsed'] = parsed_results\n",
    "    df_result['final7_parse_error'] = parse_status\n",
    "    df_result['fail_reason_final7'] = fail_reasons\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0edcf1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš¨ ìµœì¢… 7ì°¨ íŒŒì‹± ì‹¤íŒ¨ ìˆ˜: 1ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_86978/3228547639.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_fail_final6 = df_final6[df_final6['final6_parse_error'].fillna(False)]\n"
     ]
    }
   ],
   "source": [
    "# 1ï¸âƒ£ ì´ì „ê¹Œì§€ ì‹¤íŒ¨í•œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_fail_final6 = df_final6[df_final6['final6_parse_error'].fillna(False)]\n",
    "\n",
    "# 2ï¸âƒ£ 7ì°¨ íŒŒì‹± ì ìš©\n",
    "df_final7 = apply_final7_parsing(df_fail_final6)\n",
    "\n",
    "# 3ï¸âƒ£ íŒŒì‹± ì‹¤íŒ¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
    "df_fail_final7 = df_final7[df_final7['final7_parse_error'].fillna(False)]\n",
    "\n",
    "# 4ï¸âƒ£ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"ğŸš¨ ìµœì¢… 7ì°¨ íŒŒì‹± ì‹¤íŒ¨ ìˆ˜: {len(df_fail_final7)}ê°œ\")\n",
    "\n",
    "# 5ï¸âƒ£ CSV ì €ì¥\n",
    "df_fail_final7.to_csv('supplement_parse_errors_final7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3ca12",
   "metadata": {},
   "source": [
    "## ìµœì¢… íŒŒì‹± ì™„ë£Œëœ ë°ì´í„° í™•ì¸í•˜ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b2730d2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (325)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ì „ì²´ ë°ì´í„° ë¶ˆëŸ¬ì˜¨ ì›ë³¸ì´ df_supp_checkedë¼ê³  ê°€ì •\u001b[39;00m\n\u001b[32m      2\u001b[39m df_total = df_supp_checked.copy()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdf_total\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparsed_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = df_final7[\u001b[33m'\u001b[39m\u001b[33mfinal7_parsed\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      5\u001b[39m df_total[\u001b[33m'\u001b[39m\u001b[33mparse_error\u001b[39m\u001b[33m'\u001b[39m] = df_final7[\u001b[33m'\u001b[39m\u001b[33mfinal7_parse_error\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      6\u001b[39m df_total[\u001b[33m'\u001b[39m\u001b[33mfail_reason\u001b[39m\u001b[33m'\u001b[39m] = df_final7[\u001b[33m'\u001b[39m\u001b[33mfail_reason_final7\u001b[39m\u001b[33m'\u001b[39m].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/frame.py:4316\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4313\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4315\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4316\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/frame.py:4529\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4520\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4521\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4522\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4527\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4529\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4532\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4533\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4534\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4535\u001b[39m     ):\n\u001b[32m   4536\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4537\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/frame.py:5273\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5273\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5274\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5276\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5277\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5280\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5281\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.2/lib/python3.13/site-packages/pandas/core/common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (2) does not match length of index (325)"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„° ë¶ˆëŸ¬ì˜¨ ì›ë³¸ì´ df_supp_checkedë¼ê³  ê°€ì •\n",
    "df_total = df_supp_checked.copy()\n",
    "\n",
    "df_total['parsed_data'] = df_final7['final7_parsed'].values\n",
    "df_total['parse_error'] = df_final7['final7_parse_error'].values\n",
    "df_total['fail_reason'] = df_final7['fail_reason_final7'].values\n",
    "# ìš”ì•½ í†µê³„\n",
    "total = len(df_total)\n",
    "num_success = (df_total['parse_error'] == False).sum()\n",
    "num_fail = (df_total['parse_error'] == True).sum()\n",
    "num_na = df_total['parse_error'].isna().sum()\n",
    "\n",
    "print(f\"ğŸ“Š ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total}\")\n",
    "print(f\"âœ… íŒŒì‹± ì„±ê³µ: {num_success}ê°œ\")\n",
    "print(f\"âŒ íŒŒì‹± ì‹¤íŒ¨: {num_fail}ê°œ\")\n",
    "print(f\"â“ ìƒíƒœ ë¯¸í™•ì¸ (NaN): {num_na}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ef2f965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¨¼ì € df_final7ì— ì¸ë±ìŠ¤ ì •ë³´ë¥¼ ì¶”ê°€ (ì˜ˆ: ì›ë˜ ì¸ë±ìŠ¤ ìœ ì§€)\n",
    "df_final7 = df_final7.copy()\n",
    "df_final7['original_index'] = df_final7.index\n",
    "\n",
    "# df_totalì—ë„ ì¸ë±ìŠ¤ ì •ë³´ ë¶€ì—¬\n",
    "df_total = df_supp_checked.copy()\n",
    "df_total['original_index'] = df_total.index\n",
    "\n",
    "# merge: ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©\n",
    "df_total = df_total.merge(\n",
    "    df_final7[['original_index', 'final7_parsed', 'final7_parse_error', 'fail_reason_final7']],\n",
    "    on='original_index',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ì»¬ëŸ¼ ì •ë¦¬\n",
    "df_total.rename(columns={\n",
    "    'final7_parsed': 'parsed_data',\n",
    "    'final7_parse_error': 'parse_error',\n",
    "    'fail_reason_final7': 'fail_reason'\n",
    "}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
