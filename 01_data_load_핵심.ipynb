{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a349863b",
   "metadata": {},
   "source": [
    "# 데이터 구조 이해 & SQL 스키마 설계\n",
    "- JSON 데이터 로드 및 컬럼 확인 (pandas)\n",
    "- 결측치·중복 데이터 확인/정제\n",
    "- SQL DB 스키마 설계 (Supplements, Ingredients, Supplement_Ingredients, Symptoms_Ingredients)• 증상–성분 매핑 테이블 초안 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1689c",
   "metadata": {},
   "source": [
    "- json 파일 데이터 개수: 1241개, 23열 ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d51a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) 로드\n",
    "fp = '/Users/gim-yujin/Desktop/pjt_personal_agent/영양소 데이터/JSON 파일 /iherb_data_uk_data_2022_12.json'\n",
    "df = pd.read_json(fp, orient='records')   # 파일이 리스트 of dicts 여야 정상\n",
    "# 2) 전체 컬럼 확인\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "# 3) 샘플 확인\n",
    "display(df.head())\n",
    "# 4) 기본 타입 정리\n",
    "df['scraped_at'] = pd.to_datetime(df['scraped_at'], dayfirst=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##컬럼명 목록\")\n",
    "print(df.columns)\n",
    "print(\"-\" * 50)\n",
    "# 컬럼별 결측치 개수 확인 \n",
    "print(\"##컬럼별 결측치 개수 확인(공백 문자열이 결측치로 합산이 안되어 모두 0으로 표기됨)\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Supplement Facts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc363c",
   "metadata": {},
   "source": [
    "### 결측치 확인\n",
    "- 결측값이 존재하는 컬럼 및 개수\n",
    "- Category 2            4\n",
    "- Category 3          869\n",
    "- ingredients          61\n",
    "- Supplement Facts    530 (추후에 성분을 참고하여 채워 넣을 예정, 보충정보(영양성분))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (선택) 모든 컬럼에 대해 한 번에 적용할 수도 있습니다.\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "print(\"\\n## 전체 데이터의 실제 결측치 수\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  각 컬럼의 결측치 개수를 계산\n",
    "missing_values = df.isnull().sum()\n",
    "#  결측치 개수가 0보다 큰 컬럼들만 필터링하여 출력합니다.\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(\"## 결측값이 존재하는 컬럼 및 개수\")\n",
    "if columns_with_missing_values.empty:\n",
    "    print(\"모든 컬럼의 데이터가 채워져 있습니다.\")\n",
    "else:\n",
    "    print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4081542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측값이 존재하는 컬럼 선택 출력 확인 \n",
    "\n",
    "df_missing = df[columns_with_missing_values.index]\n",
    "print(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6827246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_with_missing_values.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6230bf",
   "metadata": {},
   "source": [
    "### 중복 제거 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98231d0a",
   "metadata": {},
   "source": [
    "- unique_id 기준(0)\n",
    "- Pid, title 기준(0)\n",
    "- 중복되는 아이템은 없음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75738431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거 (uniqe_id 기준으로는 중복 없음.)\n",
    "df = df.drop_duplicates(subset=['uniq_id'])  \n",
    "# uniq_id가 있으면 안전\n",
    "df.drop_duplicates(subset=['Pid','Title'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86011d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Pid','Title']) #여기도 중복은 없는 것으로 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'] = df['Price'].astype(str)\n",
    "# price >> 문자열로 공백/ 쉼표 제고후 float\n",
    "df['Price'] = df['Price'].str.replace(',', '').str.strip()\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb30a6",
   "metadata": {},
   "source": [
    "### 불필요한 레코드 필터링 \n",
    "- 카테고리 1, 2 기준으로 키워드 필터링 한 결과, 해당 데이터셋에서 영양제와 관련된 상품 개수는 1221->325 개로 감소함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 화장품/ 샴푸/ 식품/ 베이비 용품 등 필터링 \n",
    "non_supp_cats = ['Shampoo','Foundation','Face Wash','Utensils','Diapers']  # 예시\n",
    "df = df[~df['Category 2'].isin(non_supp_cats)]\n",
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Category 1' 컬럼의 모든 고유값 출력\n",
    "print(\"Category 1의 고유값:\", df['Category 1'].unique())\n",
    "\n",
    "# 'Category 2' 컬럼의 모든 고유값 출력\n",
    "print(\"Category 2의 고유값:\", df['Category 2'].unique())\n",
    "\n",
    "# 'Category 3' 컬럼의 모든 고유값 출력\n",
    "print(\"Category 3의 고유값:\", df['Category 3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 화이트리스트 키워드(supp_keywords)\n",
    "\n",
    "supp_keywords = [\n",
    "    # 비타민·미네랄\n",
    "    'vitamin', 'multivitamin', 'multimineral', 'b1', 'b2', 'b3', 'b6',\n",
    "    'b12', 'c', 'd', 'e', 'k', 'folic acid', 'niacin', 'biotin',\n",
    "    'calcium', 'magnesium', 'zinc', 'iron', 'selenium', 'potassium',\n",
    "    'iodine', 'trace minerals',\n",
    "\n",
    "    # 오메가 & 필수지방산\n",
    "    'omega', 'fish oil', 'krill oil', 'cod liver oil',\n",
    "    'efa', 'dha', 'epa',\n",
    "\n",
    "    # 허브·식물 추출물\n",
    "    'herb', 'herbal', 'ashwagandha', 'ginseng', 'echinacea', 'turmeric',\n",
    "    'curcumin', 'milk thistle', 'rhodiola', 'elderberry', 'boswellia',\n",
    "    'sambucus', 'hawthorn', 'garlic', 'ginger', 'licorice', 'oregano',\n",
    "    'passion flower', 'valerian', 'chamomile', 'nettle', 'schisandra',\n",
    "    'astragalus',\n",
    "\n",
    "    # 아미노산·단백질\n",
    "    'amino', 'amino acid', 'l-',   # L-Arginine, L-Tyrosine 등 앞에 L-이 붙음\n",
    "    'protein', 'collagen', 'peptide',\n",
    "\n",
    "    # 프로바이오틱/소화\n",
    "    'probiotic', 'prebiotic', 'lactobacillus', 'bifidus',\n",
    "    'digestive enzymes', 'enzyme',\n",
    "\n",
    "    # 항산화·기타 보조성분\n",
    "    'coq10', 'ubiquinol', 'alpha lipoic acid', 'resveratrol',\n",
    "    'pycnogenol', 'glutathione', 'chlorophyll', 'spirulina',\n",
    "    'chlorella', 'maca', 'bee pollen', 'royal jelly',\n",
    "\n",
    "    # 특수 목적 포뮬러\n",
    "    'immune', 'immune support', 'energy formula', 'sleep formula',\n",
    "    'cognitive', 'memory', 'joint', 'bone', 'liver', 'thyroid',\n",
    "    'blood support', 'heart support', 'detox', 'women\\'s health',\n",
    "    'men\\'s health', 'prenatal', 'post-natal',\n",
    "    'sports supplement', 'workout', 'weight management', 'fat burner',\n",
    "\n",
    "    # 형태·일반명\n",
    "    'supplement', 'dietary', 'nutrition', 'nutrient',\n",
    "    'superfood', 'greens', 'superfood blend'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_supplement_row(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return any(re.search(rf\"\\b{k}\\b\", cats) for k in supp_keywords)\n",
    "\n",
    "df_supp = df[df.apply(is_supplement_row, axis=1)].copy()\n",
    "\n",
    "print(f\"필터 전 {len(df)} → 필터 후 {len(df_supp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939af01",
   "metadata": {},
   "source": [
    "### 제대로 필터링 되었는지 확인 작업\n",
    "- 멀티비타민과, 비타민 구분하여 놓았는지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1️⃣ 화이트리스트 기반 영양제 필터\n",
    "def is_supplement_row(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return any(re.search(rf\"\\b{k}\\b\", cats) for k in supp_keywords)\n",
    "\n",
    "df_supp = df[df.apply(is_supplement_row, axis=1)].copy()\n",
    "\n",
    "# 2️⃣ 블랙리스트 제거 (현재는 K-Beauty 하나지만 확장 가능)\n",
    "black_keywords = ['k-beauty']\n",
    "def not_blacklisted(row):\n",
    "    cats = \" \".join([\n",
    "        str(row.get('Category 1', '')).lower(),\n",
    "        str(row.get('Category 2', '')).lower(),\n",
    "        str(row.get('Category 3', '')).lower()\n",
    "    ])\n",
    "    return not any(bk in cats for bk in black_keywords)\n",
    "\n",
    "df_supp = df_supp[df_supp.apply(not_blacklisted, axis=1)].copy()\n",
    "\n",
    "print(f\"최종 필터 후 행 수 : {len(df_supp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ 무작위 100건 추출 (중복 없이)\n",
    "sample_100 = df_supp.sample(n=100, random_state=42)  # random_state는 재현성\n",
    "\n",
    "# 4️⃣ 검토에 유용한 컬럼만 보기\n",
    "cols_to_check = ['Title', 'Category 1', 'Category 2', 'Category 3', 'Description']\n",
    "print(sample_100[cols_to_check].to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b5875d",
   "metadata": {},
   "source": [
    "### “파싱(parsing)”: 문자열(예: Supplement Facts 텍스트) 안에서 우리가 원하는 정보(성분명, 용량, 단위 등)를 규칙적으로 뽑아내는 작업\n",
    "\n",
    "- 1.\tparse_supplement_facts()\n",
    "→ 텍스트를 줄 단위로 읽고 정규식으로 [성분, 수치, 단위] 추출.\n",
    "- 2.\tparse_and_flag()\n",
    "→ 전체 DataFrame에 적용, parsed_ingredients와 parse_error 컬럼 추가.\n",
    "- 3.\t수동 검토\n",
    "→ parse_error=True인 레코드만 CSV로 내보내어 직접 확인·수정.\n",
    "--- \n",
    "- df_supp_checked\n",
    "\n",
    "- parsed_ingredients: 파싱 성공 시 [{'name':…, 'amount':…, 'unit':…}, …] 리스트\n",
    "\n",
    "- parse_error: True(실패) / False(성공)\n",
    "\n",
    "- supplement_parse_errors.csv\n",
    "\n",
    "사람이 직접 살펴보고 정규식 보완이나 데이터 수동 입력이 필요한 상품 목록.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pattern = r'(?i)' + '|'.join([re.escape(k) for k in supp_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_supplement_facts(text):\n",
    "    \"\"\"\n",
    "    Supplement Facts 문자열에서\n",
    "    [성분명, 수치, 단위] 추출\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return results  # 빈 값이면 바로 실패\n",
    "    \n",
    "    # 예) \"Vitamin C 500 mg\", \"Magnesium (as oxide) 250 mg\"\n",
    "    pattern = r'([A-Za-z0-9\\-\\(\\) /]+?)\\s+([\\d.,]+)\\s*(mg|mcg|µg|g|iu|IU)'\n",
    "    \n",
    "    for line in text.splitlines():\n",
    "        m = re.search(pattern, line)\n",
    "        if m:\n",
    "            name = m.group(1).strip()\n",
    "            amount = float(m.group(2).replace(',', ''))\n",
    "            unit = m.group(3).lower()\n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'amount': amount,\n",
    "                'unit': unit,\n",
    "                'raw_line': line.strip()\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_flag_supp(df_supp):\n",
    "    parsed_results = []\n",
    "    parse_error_flags = []\n",
    "\n",
    "    for text in df_supp['Supplement Facts']:\n",
    "        parsed = parse_supplement_facts(text)\n",
    "        parsed_results.append(parsed)\n",
    "        # 파싱 결과가 없으면 True → 실패\n",
    "        parse_error_flags.append(len(parsed) == 0)\n",
    "\n",
    "    df_supp_checked = df_supp.copy()\n",
    "    df_supp_checked['parsed_ingredients'] = parsed_results\n",
    "    df_supp_checked['parse_error'] = parse_error_flags\n",
    "    return df_supp_checked\n",
    "\n",
    "# ✅ 실행\n",
    "df_supp_checked = parse_and_flag_supp(df_supp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_supp_checked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5998bd",
   "metadata": {},
   "source": [
    "### 파싱 실패 레코드 처리 \n",
    "- HTML 태그 제거\n",
    "\n",
    "- Proprietary / Matrix / Blend 감지\n",
    "\n",
    "- 다중 %DV 항목 탐지\n",
    "\n",
    "- Serving Size, Amount Per Serving 기반 구조성 여부 판단\n",
    "\n",
    "결과: parsed, 또는 실패한 경우 실패 사유 코드 리턴 -->\n",
    "1.\t다양한 줄바꿈 (\\n, \\r\\n) 혹은 공백을 제거하여 일관성 있게 처리\n",
    "2.\tServing Size, Amount Per Serving, % Daily Value 등 핵심 키워드를 기준으로 텍스트를 구조화\n",
    "3.\t영양소 정보 블록을 정확히 추출\n",
    "4.\tMarkdown 또는 HTML 태그, 기호 (†, ‡) 제거\n",
    "5.\t공란 또는 비정상 케이스에 대해 안전하게 예외 처리\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895ce54",
   "metadata": {},
   "source": [
    "- 텍스 자체가 난해하거나, 보충제가 아닌 상품이 섞여있어 위의 많은 시도에서 실패한 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670fb4a",
   "metadata": {},
   "source": [
    "-복잡한 블랜드나 표기 단위생략,불규칙한 경우는 여전히 파싱이 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8b3ed",
   "metadata": {},
   "source": [
    "# 전체 통합 정리 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ 전체 데이터프레임: df_supp_checked 는 초기 전체 325개 데이터라고 가정\n",
    "df_failed = df_supp_checked[df_supp_checked['parse_error']]  # 1차 파싱 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba21a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시: 7차 파싱 함수 (최신 버전으로 대체)\n",
    "def parse_supplement_facts_v7(text):\n",
    "    import re\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"공란 또는 타입 오류\", \"data\": None}\n",
    "    \n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', text.strip())\n",
    "    block = re.sub(r'[†‡*%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block)\n",
    "\n",
    "    pattern = r'([A-Za-z0-9 \\-–®™\\(\\)\\[\\],\\'+°]+?)\\s+([\\d\\.,]+)\\s*(mcg|mg|g|iu|IU|%)?'\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(\",\", \"\")),\n",
    "                \"unit\": unit or \"\"\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"성분 추출 실패\",\n",
    "        \"data\": nutrients if nutrients else None\n",
    "    }\n",
    "\n",
    "# ✅ 통합 적용 함수\n",
    "def apply_final_parsing_v7(df):\n",
    "    parsed_results = []\n",
    "    parse_status = []\n",
    "    fail_reasons = []\n",
    "\n",
    "    for text in df['Supplement Facts']:\n",
    "        result = parse_supplement_facts_v7(text)\n",
    "        parsed_results.append(result['data'])\n",
    "        parse_status.append(result['status'] == 'fail')\n",
    "        fail_reasons.append(result['reason'] if result['status'] == 'fail' else None)\n",
    "\n",
    "    df_result = df.copy()\n",
    "    df_result['final7_parsed'] = parsed_results\n",
    "    df_result['final7_parse_error'] = parse_status\n",
    "    df_result['fail_reason_final7'] = fail_reasons\n",
    "\n",
    "    return df_result\n",
    "\n",
    "# ✅ 7차 파싱 실행\n",
    "df_final7 = apply_final_parsing_v7(df_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 DataFrame 복사\n",
    "df_total = df_supp_checked.copy()\n",
    "\n",
    "# 컬럼 초기화 (초기값은 기존 결과)\n",
    "df_total['final_parsed']      = df_total.get('parsed_ingredients', None)\n",
    "df_total['final_parse_error'] = df_total.get('parse_error', None)\n",
    "df_total['final_fail_reason'] = df_total.get('fail_reason', None)\n",
    "\n",
    "# 7차 파싱된 인덱스를 기준으로 덮어쓰기\n",
    "idx = df_final7.index\n",
    "df_total.loc[idx, 'final_parsed']      = df_final7['final7_parsed']\n",
    "df_total.loc[idx, 'final_parse_error'] = df_final7['final7_parse_error']\n",
    "df_total.loc[idx, 'final_fail_reason'] = df_final7['fail_reason_final7']\n",
    "\n",
    "# 성공한 경우 실패 사유 제거\n",
    "df_total.loc[df_total['final_parse_error'] == False, 'final_fail_reason'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 성공 / 실패 / 누락 개수 확인\n",
    "total = len(df_total)\n",
    "num_success = (df_total['final_parse_error'] == False).sum()\n",
    "num_fail = (df_total['final_parse_error'] == True).sum()\n",
    "num_na = df_total['final_parse_error'].isna().sum()\n",
    "\n",
    "print(f\"📊 전체 레코드 수: {total}\")\n",
    "print(f\"✅ 파싱 성공: {num_success}개\")\n",
    "print(f\"❌ 파싱 실패: {num_fail}개\")\n",
    "print(f\"❓ 상태 미확인 (NaN): {num_na}개\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127cc9a",
   "metadata": {},
   "source": [
    "# 성분 추출 실패 파일 만들기 위해 추가한 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.columns\n",
    "#df_total['fail_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"전체 개수:\", len(df_total['final_fail_reason']))\n",
    "print(\"실패 사유가 있는 행 수:\", df_total['final_fail_reason'].notna().sum())\n",
    "print(\"실패 사유가 없는 행 수 (NaN):\", df_total['final_fail_reason'].isna().sum())\n",
    "print(df_total['final_fail_reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff630363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 supplement_failed_성분추출실패.csv 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ 성분 추출 실패한 데이터만 필터링\n",
    "df_failed_extracted = df_total[df_total['final_fail_reason'] == '성분 추출 실패'].copy()\n",
    "\n",
    "# 2️⃣ 필요한 컬럼만 선택해서 확인\n",
    "columns_to_save = [\n",
    "    \"Title\",\n",
    "    \"Category 1\", \"Category 2\", \"Category 3\",\n",
    "    \"Brand\",\n",
    "    \"Supplement Facts\",\n",
    "    \"Description\",\n",
    "    \"final_fail_reason\"\n",
    "]\n",
    "\n",
    "df_failed_export = df_failed_extracted[columns_to_save]\n",
    "\n",
    "# 3️⃣ CSV로 저장\n",
    "df_failed_export.to_csv(\"supplement_failed_성분추출실패.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"📁 supplement_failed_성분추출실패.csv 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 정렬 후 병합 (권장)\n",
    "df_total['fail_reason'] = df_final7['fail_reason_final7'].reindex(df_total.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac375dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fail_reason' not in df_total.columns:\n",
    "    print(\"⚠️ 'fail_reason' 컬럼이 없습니다. 먼저 추가해 주세요.\")\n",
    "else:\n",
    "    print(df_total['fail_reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d43ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성분 추출 실패한 92개 개선 \n",
    "def parse_supplement_facts_v8(text: str) -> dict:\n",
    "    import re\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"공란 또는 타입 오류\", \"data\": None}\n",
    "\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', text.strip())\n",
    "    block = re.sub(r'[†‡*%]+', '', block)\n",
    "    block = re.sub(r'\\s{2,}', ' ', block)\n",
    "\n",
    "    # 좀 더 자유롭게 괄호와 단위 허용\n",
    "    pattern = r'([A-Za-z0-9 \\-–®™\\(\\)\\[\\],\\'°©®]+?)\\s*[:\\-]?\\s*([\\d\\.,]+)\\s*(mcg|mg|g|iu|IU|ml|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"성분 추출 실패\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(',', '')),\n",
    "                \"unit\": unit or ''\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"성분 추출 실패\",\n",
    "        \"data\": nutrients,\n",
    "        \"count\": len(nutrients)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fail = df_total[df_total['final_parse_error']]\n",
    "df_retry8 = df_fail.copy()\n",
    "\n",
    "# 새로 파싱 시도\n",
    "results = df_retry8['Supplement Facts'].apply(parse_supplement_facts_v8)\n",
    "\n",
    "df_retry8['final8_parsed'] = results.map(lambda x: x['data'])\n",
    "df_retry8['final8_parse_error'] = results.map(lambda x: x['status'] == 'fail')\n",
    "df_retry8['fail_reason_final8'] = results.map(lambda x: x['reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef172d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 index가 일치하는지 확인 (안하면 오류납니다!)\n",
    "df_retry8 = df_retry8.copy()\n",
    "df_retry8 = df_retry8[['final8_parsed', 'final8_parse_error', 'fail_reason_final8']]\n",
    "\n",
    "# 원본 df_total에 있는 실패 데이터의 인덱스 기준으로 업데이트\n",
    "df_total.loc[df_retry8.index, 'parsed_data'] = df_retry8['final8_parsed']\n",
    "df_total.loc[df_retry8.index, 'parse_error'] = df_retry8['final8_parse_error']\n",
    "df_total.loc[df_retry8.index, 'fail_reason'] = df_retry8['fail_reason_final8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf58e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 성공/실패/NaN 통계 요약\n",
    "total = len(df_total)\n",
    "num_success = (df_total['parse_error'] == False).sum()\n",
    "num_fail = (df_total['parse_error'] == True).sum()\n",
    "num_na = df_total['parse_error'].isna().sum()\n",
    "\n",
    "print(f\"📊 전체 레코드 수: {total}\")\n",
    "print(f\"✅ 파싱 성공: {num_success}개\")\n",
    "print(f\"❌ 파싱 실패: {num_fail}개\")\n",
    "print(f\"❓ 상태 미확인 (NaN): {num_na}개\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0236c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_summary = df_total[df_total['parse_error'] == True]['fail_reason'].value_counts()\n",
    "print(\"\\n📉 파싱 실패 사유 분포:\")\n",
    "print(fail_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045414ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실패한 레코드 중에서 실패 사유가 비어 있는 (NaN) 데이터\n",
    "df_fail = df_total[df_total['parse_error'] == True]\n",
    "df_fail_nan_reason = df_fail[df_fail['fail_reason'].isna()]\n",
    "\n",
    "print(f\"❓ 실패했지만 실패 사유가 없는 레코드 수: {len(df_fail_nan_reason)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실패 사유가 없는 데이터만 저장\n",
    "df_fail_nan_reason.to_csv('supplement_parsing_failed_reason_missing.csv', index=False)\n",
    "print(\"📁 supplement_parsing_failed_reason_missing.csv 파일로 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 실패한 106개 레코드만 필터링\n",
    "df_fail = df_total[df_total['parse_error'] == True]\n",
    "\n",
    "# 컬럼 목록 출력\n",
    "print(\"📋 파싱 실패한 데이터프레임의 컬럼 목록:\")\n",
    "print(df_fail.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b375cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_total.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = df_total[df_total['final_parse_error'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 즉, **parse_error 컬럼을 기준으로 했기 때문에 219개**로 나왔던 것이고,\n",
    "# final_parse_error 기준은 214개입니다\n",
    "\n",
    "len(df_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9688915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 최종 파싱 성공한 데이터만 필터링\n",
    "df_parsed = df_total[df_total['final_parse_error'] == False]\n",
    "\n",
    "# ✅ CSV 파일로 저장\n",
    "df_parsed.to_csv(\"parsed_supplements_final.csv\", index=False)\n",
    "print(\"✅ 파싱된 데이터가 'parsed_supplements_final.csv'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f51f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e25fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예: 인덱스 6번의 전체 데이터 보기\n",
    "import pprint\n",
    "pprint.pprint(df_parsed['final_parsed'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ parsed_data 컬럼 제거\n",
    "df_parsed.drop(columns=['parsed_data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed.to_csv(\"parsed_supplements_final_cleaned.csv\", index=False)\n",
    "print(\"✅ cleaned 파일 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bb505",
   "metadata": {},
   "source": [
    "## 컬럼명 정리\n",
    "final_parsed\n",
    "✅ 최종 파싱 결과 리스트 ([{name, amount, unit, ...}, ...] 형태). 실제로 Supplement Facts를 정규표현식으로 파싱한 결과입니다.\n",
    "final_parse_error\n",
    "✅ 파싱 성공 여부를 담은 True/False 값. True면 파싱 실패, False면 성공입니다.\n",
    "final_fail_reason\n",
    "✅ 파싱 실패 이유를 설명하는 텍스트. 예: \"성분 추출 실패\", \"공란 또는 타입 오류\" 등\n",
    "fail_reason\n",
    "(중간 버전에서 사용하던) 파싱 실패 사유. 지금은 final_fail_reason이 최신이므로 이건 거의 NaN 상태일 수 있어요.\n",
    "parsed_data\n",
    "❌ 초기 파싱 때 쓰던 결과 컬럼인데, 지금은 쓰지 않아요. 최종 결과는 final_parsed로 대체되었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_parsed['fail_reason'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddff748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4a1be",
   "metadata": {},
   "source": [
    "# 8차 파싱 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36274e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_supplement_facts_v8(text: str) -> dict:\n",
    "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"status\": \"fail\", \"reason\": \"공란 또는 타입 오류\", \"data\": None}\n",
    "\n",
    "    # 1️⃣ 특수문자 및 공백 정리\n",
    "    block = re.sub(r'[\\n\\r\\t]', ' ', text.strip())  # 줄바꿈 제거\n",
    "    block = re.sub(r'[†‡*%•●◆…–—✔️→→▶→➡️★]', '', block)  # 특수문자 제거\n",
    "    block = re.sub(r'\\s{2,}', ' ', block)  # 다중 공백 정리\n",
    "    block = re.sub(r'(\\d)([A-Za-z])', r'\\1 \\2', block)  # 숫자와 문자가 붙어있는 경우 분리\n",
    "    block = re.sub(r'([A-Za-z])(\\d)', r'\\1 \\2', block)  # 문자와 숫자가 붙어있는 경우 분리\n",
    "\n",
    "    # 2️⃣ 정규식 개선: 성분명에는 괄호, 대괄호, 상표까지 허용\n",
    "    # 예: \"Zinc (as Zinc Gluconate)\" 또는 \"Selenium [from Selenium Yeast]\"\n",
    "    pattern = r'([A-Za-z0-9 \\-–®™\\(\\)\\[\\],\\'°©®\\/&]+?)\\s*[:\\-]?\\s*([\\d\\.,]+)\\s*(mg|mcg|g|IU|iu|ml|billion CFU|CFU|ALU|HUT|XU|DP|SU|CU|FIP|DPPU|%)?'\n",
    "\n",
    "    matches = re.findall(pattern, block)\n",
    "\n",
    "    if not matches:\n",
    "        return {\"status\": \"fail\", \"reason\": \"성분 추출 실패\", \"data\": None}\n",
    "\n",
    "    nutrients = []\n",
    "    for name, amount, unit in matches:\n",
    "        try:\n",
    "            nutrients.append({\n",
    "                \"name\": name.strip(),\n",
    "                \"amount\": float(amount.replace(',', '')),\n",
    "                \"unit\": unit or '',\n",
    "                \"raw_line\": block  # 원본 라인 전체 저장\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\" if nutrients else \"fail\",\n",
    "        \"reason\": None if nutrients else \"성분 추출 실패\",\n",
    "        \"data\": nutrients if nutrients else None,\n",
    "        \"count\": len(nutrients)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f167f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_96580/665848918.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed['final8_parsed'] = results.map(lambda x: x['data'])\n",
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_96580/665848918.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed['final8_parse_error'] = results.map(lambda x: x['status'] == 'fail')\n",
      "/var/folders/98/vj3q9b254k79y681ng12dddh0000gn/T/ipykernel_96580/665848918.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_failed['fail_reason_final8'] = results.map(lambda x: x['reason'])\n"
     ]
    }
   ],
   "source": [
    "# 실패한 데이터만 추출\n",
    "df_failed = df_total[df_total['final_parse_error']]\n",
    "\n",
    "# 새 파싱 적용\n",
    "results = df_failed['Supplement Facts'].apply(parse_supplement_facts_v8)\n",
    "\n",
    "# 결과 반영\n",
    "df_failed['final8_parsed'] = results.map(lambda x: x['data'])\n",
    "df_failed['final8_parse_error'] = results.map(lambda x: x['status'] == 'fail')\n",
    "df_failed['fail_reason_final8'] = results.map(lambda x: x['reason'])\n",
    "\n",
    "# 병합\n",
    "df_total = df_total.copy()\n",
    "df_total.loc[df_failed.index, 'final8_parsed'] = df_failed['final8_parsed']\n",
    "df_total.loc[df_failed.index, 'final8_parse_error'] = df_failed['final8_parse_error']\n",
    "df_total.loc[df_failed.index, 'fail_reason_final8'] = df_failed['fail_reason_final8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc7606a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 전체 레코드 수: 325\n",
      "✅ 파싱 성공: 92개\n",
      "❌ 파싱 실패: 19개\n",
      "❓ 상태 미확인 (NaN): 214개\n"
     ]
    }
   ],
   "source": [
    "# 성공: 파싱 에러가 False\n",
    "num_success = (df_total['final8_parse_error'] == False).sum()\n",
    "\n",
    "# 실패: 파싱 에러가 True\n",
    "num_fail = (df_total['final8_parse_error'] == True).sum()\n",
    "\n",
    "# 누락: 값 자체가 NaN (파싱 시도되지 않은 경우 포함 가능)\n",
    "num_nan = df_total['final8_parse_error'].isna().sum()\n",
    "\n",
    "print(f\"📦 전체 레코드 수: {len(df_total)}\")\n",
    "print(f\"✅ 파싱 성공: {num_success}개\")\n",
    "print(f\"❌ 파싱 실패: {num_fail}개\")\n",
    "print(f\"❓ 상태 미확인 (NaN): {num_nan}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2def7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱 성공 데이터 저장\n",
    "df_success = df_total[df_total['final8_parse_error'] == False]\n",
    "df_success.to_csv(\"supplements_parsed_success_final8.csv\", index=False)\n",
    "\n",
    "# # 파싱 실패 데이터 저장\n",
    "# df_fail = df_total[df_total['final8_parse_error'] == True]\n",
    "# df_fail.to_csv(\"supplements_parsed_failed_final8.csv\", index=False)\n",
    "\n",
    "# # 누락 (NaN) 데이터 저장\n",
    "# df_na = df_total[df_total['final8_parse_error'].isna()]\n",
    "# df_na.to_csv(\"supplements_parsed_unknown_final8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "745c6c51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rag_data\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 변환 및 저장\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m rag_json = \u001b[43mdf_to_rag_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_success\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msupplements_rag_data_final8.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     28\u001b[39m     json.dump(rag_json, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mdf_to_rag_json\u001b[39m\u001b[34m(df, parsed_col)\u001b[39m\n\u001b[32m      4\u001b[39m rag_data = []\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m      7\u001b[39m     entry = {\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m: [row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m), row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m), row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbrand\u001b[39m\u001b[33m\"\u001b[39m: row.get(\u001b[33m\"\u001b[39m\u001b[33mBrand\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupplement_facts\u001b[39m\u001b[33m\"\u001b[39m: row.get(parsed_col, []),\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: row.get(\u001b[33m\"\u001b[39m\u001b[33mDescription\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m({\n\u001b[32m     14\u001b[39m             *(\u001b[38;5;28mstr\u001b[39m(row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)).split()),\n\u001b[32m     15\u001b[39m             *(\u001b[38;5;28mstr\u001b[39m(row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)).split()),\n\u001b[32m     16\u001b[39m             *(\u001b[38;5;28mstr\u001b[39m(row.get(\u001b[33m\"\u001b[39m\u001b[33mCategory 3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)).split()),\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             *\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m         })\n\u001b[32m     19\u001b[39m     }\n\u001b[32m     20\u001b[39m     rag_data.append(entry)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rag_data\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def df_to_rag_json(df, parsed_col='final_parsed'):\n",
    "    rag_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        entry = {\n",
    "            \"title\": row[\"Title\"],\n",
    "            \"category\": [row.get(\"Category 1\", \"\"), row.get(\"Category 2\", \"\"), row.get(\"Category 3\", \"\")],\n",
    "            \"brand\": row.get(\"Brand\", \"\"),\n",
    "            \"supplement_facts\": row.get(parsed_col, []),\n",
    "            \"description\": row.get(\"Description\", \"\"),\n",
    "            \"tags\": list({\n",
    "                *(str(row.get(\"Category 1\", \"\")).split()),\n",
    "                *(str(row.get(\"Category 2\", \"\")).split()),\n",
    "                *(str(row.get(\"Category 3\", \"\")).split()),\n",
    "                *(i[\"name\"] for i in row.get(parsed_col, []) if isinstance(i, dict))\n",
    "            })\n",
    "        }\n",
    "        rag_data.append(entry)\n",
    "\n",
    "    return rag_data\n",
    "\n",
    "# 변환 및 저장\n",
    "rag_json = df_to_rag_json(df_success)\n",
    "\n",
    "with open(\"supplements_rag_data_final8.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rag_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"📦 'supplements_rag_data_final8.json' 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "174590d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON 파일 저장 완료: supplements_rag_data_final8.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def df_to_rag_json(df, parsed_col='final_parsed'):\n",
    "    rag_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        parsed_data = row.get(parsed_col)\n",
    "        if not isinstance(parsed_data, list):\n",
    "            parsed_data = []  # None 또는 문자열이면 빈 리스트로\n",
    "\n",
    "        entry = {\n",
    "            \"title\": row[\"Title\"],\n",
    "            \"category\": [row.get(\"Category 1\", \"\"), row.get(\"Category 2\", \"\"), row.get(\"Category 3\", \"\")],\n",
    "            \"brand\": row.get(\"Brand\", \"\"),\n",
    "            \"supplement_facts\": parsed_data,\n",
    "            \"description\": row.get(\"Description\", \"\"),\n",
    "            \"tags\": list({\n",
    "                *(str(row.get(\"Category 1\", \"\")).split()),\n",
    "                *(str(row.get(\"Category 2\", \"\")).split()),\n",
    "                *(str(row.get(\"Category 3\", \"\")).split()),\n",
    "                *(i[\"name\"] for i in parsed_data if isinstance(i, dict) and \"name\" in i)\n",
    "            })\n",
    "        }\n",
    "        rag_data.append(entry)\n",
    "\n",
    "    return rag_data\n",
    "\n",
    "# ✅ JSON 생성 및 저장\n",
    "rag_json = df_to_rag_json(df_success)\n",
    "\n",
    "with open(\"supplements_rag_data_final8.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rag_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ JSON 파일 저장 완료: supplements_rag_data_final8.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
